diff -ruN a/src/github.com/mattbaird/elastigo/.gitignore b/src/github.com/mattbaird/elastigo/.gitignore
--- a/src/github.com/mattbaird/elastigo/.gitignore	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/.gitignore	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,24 @@
+# Compiled Object files, Static and Dynamic libs (Shared Objects)
+*.o
+*.a
+*.so
+
+# Folders
+_obj
+_test
+.DS_Store
+.vagrant
+
+# Architecture specific extensions/prefixes
+*.[568vq]
+[568vq].out
+
+*.cgo1.go
+*.cgo2.c
+_cgo_defun.c
+_cgo_gotypes.go
+_cgo_export.*
+
+_testmain.go
+
+*.exe
diff -ruN a/src/github.com/mattbaird/elastigo/.gitmodules b/src/github.com/mattbaird/elastigo/.gitmodules
--- a/src/github.com/mattbaird/elastigo/.gitmodules	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/.gitmodules	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+[submodule "java"]
+	path = java
+	url = https://github.com/cookbooks/java.git
+[submodule "cookbooks/java"]
+	path = cookbooks/java
+	url = https://github.com/cookbooks/java.git
+[submodule "cookbooks/apt"]
+	path = cookbooks/apt
+	url = https://github.com/opscode-cookbooks/apt.git
+[submodule "cookbooks/elasticsearch"]
+	path = cookbooks/elasticsearch
+	url = https://github.com/mattbaird/elasticsearch-chef.git
diff -ruN a/src/github.com/mattbaird/elastigo/HACKING.md b/src/github.com/mattbaird/elastigo/HACKING.md
--- a/src/github.com/mattbaird/elastigo/HACKING.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/HACKING.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,19 @@
+
+Testing
+-----------------
+
+To run tests, this library loads data into an elasticsearch server and tests against that.
+
+See core/test_test.go.   The data set should remain the same as it pulls a known set of github archive data.
+
+usage:
+
+	$cd core
+	
+    $go test -v -host eshost -loaddata # load the data
+    
+    $go test -v -host   # without load data, which only needs to run once
+
+Clean out the Elasticsearch index:
+    
+    http -v DELETE http://localhost:9200/github
\ No newline at end of file
diff -ruN a/src/github.com/mattbaird/elastigo/LICENSE b/src/github.com/mattbaird/elastigo/LICENSE
--- a/src/github.com/mattbaird/elastigo/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/LICENSE	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,176 @@
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
\ No newline at end of file
diff -ruN a/src/github.com/mattbaird/elastigo/README.md b/src/github.com/mattbaird/elastigo/README.md
--- a/src/github.com/mattbaird/elastigo/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/README.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,165 @@
+elastigo [![Total views](https://sourcegraph.com/api/repos/github.com/mattbaird/elastigo/counters/views.png)](https://sourcegraph.com/github.com/mattbaird/elastigo)
+========
+
+[![Build Status][1]][2]
+
+[1]: https://drone.io/github.com/mattbaird/elastigo/status.png
+[2]: https://drone.io/github.com/mattbaird/elastigo/latest
+
+A Go (Golang) based Elasticsearch client, implements core api for Indexing and searching.   GoDoc http://godoc.org/github.com/mattbaird/elastigo
+
+To get the Chef based Vagrantfile working, be sure to pull like so::
+
+    # This will pull submodules.
+    git clone --recursive git@github.com:mattbaird/elastigo.git
+
+
+status updates
+========================
+
+* *2013-9-27* Fleshing out cluster and indices APIs, updated vagrant image to 0.90.3
+* *2013-7-10* Improvements/changes to bulk indexer (includes breaking changes to support TTL),
+         Search dsl supports And/Or/Not
+    * *SearchDsl* should still be considered beta at this
+         point, there will be minor breaking changes as more of the
+         elasticsearch feature set is implemented.
+* *2013-1-26* expansion of search dsl for greater coverage
+* *2012-12-30* new bulk indexing and search dsl
+* *2012-10-12* early in development, not ready for production yet.
+
+
+Adding content to Elasticsearch
+----------------------------------------------
+
+examples:
+
+    import "github.com/mattbaird/elastigo/api"
+    import "github.com/mattbaird/elastigo/core"
+
+    type Tweet struct {
+      User     string    `json:"user"`
+      Message  string    `json:"message"`
+    }
+
+    // Set the Elasticsearch Host to Connect to
+    api.Domain = "localhost"
+    // api.Port = "9300"
+
+    // add single go struct entity
+    response, _ := core.Index(true, "twitter", "tweet", "1", Tweet{"kimchy", "Search is cool"})
+
+    // you have bytes
+    tw := Tweet{"kimchy", "Search is cool part 2"}
+    bytesLine, err := json.Marshall(tw)
+    response, _ := core.Index(true, "twitter", "tweet", "2", bytesLine)
+
+    // Bulk Indexing
+    core.IndexBulk("twitter", "tweet", "3", &time.Now(), Tweet{"kimchy", "Search is now cooler"})
+
+    // Search Using Raw json String
+    searchJson := `{
+        "query" : {
+            "term" : { "user" : "kimchy" }
+        }
+    }`
+    out, err := core.SearchRequest(true, "twitter", "tweet", searchJson, "")
+    if len(out.Hits.Hits) == 1 {
+      fmt.Println(string(out.Hits.Hits[0].Source))
+    }
+
+
+Search DSL Examples
+-------------------------
+
+A Faceted, ranged Search using the `Search DSL` :
+
+    import "github.com/mattbaird/elastigo/api"
+    import "github.com/mattbaird/elastigo/core"
+
+    // Set the Elasticsearch Host to Connect to
+    api.Domain = "localhost"
+    // api.Port = "9300"
+
+    out, err := Search("github").Size("1").Facet(
+      Facet().Fields("actor").Size("500"),
+    ).Query(
+      Query().Range(
+         Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+      ).Search("add"),
+    ).Result()
+
+A Ranged Search using the `Search DSL` :
+
+    out, err := Search("github").Type("Issues").Pretty().Query(
+      Query().Range(
+         Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+      ).Search("add"),
+    ).Result()
+
+A Simple Search using the `Search DSL` :
+
+    out, err := Search("github").Type("Issues").Size("100").Search("add").Result()
+
+
+A Direct Search using the api :
+
+    qry := map[string]interface{}{
+      "query":map[string]interface{}{
+         "term":map[string]string{"user:"kimchy"},
+      },
+    }
+    core.SearchRequest(true, "github", "Issues", qry, "", 0)
+
+A Direct Search using the query string Api :
+
+    core.SearchUri("github", "Issues", "user:kimchy", "", 0)
+
+A Filtered search `Search DSL` :
+
+    out, err := Search("github").Filter(
+      Filter().Exists("repository.name"),
+    ).Result()
+
+
+Adding content to Elasticsearch in Bulk
+----------------------------------------------
+
+example:
+
+    import "github.com/mattbaird/elastigo/api"
+    import "github.com/mattbaird/elastigo/core"
+
+    // Set the Elasticsearch Host to Connect to
+    api.Domain = "localhost"
+    // api.Port = "9300"
+
+    indexer := core.NewBulkIndexerErrors(10, 60)
+    done := make(chan bool)
+    indexer.Run(done)
+
+    go func() {
+      for errBuf := range indexer.ErrorChannel {
+        // just blissfully print errors forever
+        fmt.Println(errBuf.Err)
+      }
+    }()
+    for i := 0; i < 20; i++ {
+      indexer.Index("twitter", "user", strconv.Itoa(i), "", nil, `{"name":"bob"}`)
+    }
+    done <- true
+
+license
+=======
+    Copyright 2012 Matthew Baird, Aaron Raddon, and more!
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
diff -ruN a/src/github.com/mattbaird/elastigo/Vagrantfile b/src/github.com/mattbaird/elastigo/Vagrantfile
--- a/src/github.com/mattbaird/elastigo/Vagrantfile	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/Vagrantfile	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,29 @@
+# -*- mode: ruby -*-
+# vi: set ft=ruby :
+
+Vagrant.configure("2") do |config|
+  config.vm.box = "lucid64"
+  config.vm.box_url = "http://files.vagrantup.com/lucid64.box"
+  config.vm.network :forwarded_port, guest: 9300, host: 9300, auto_correct: true
+  config.vm.provision :shell, :inline => "gem install chef --version 10.26.0 --no-rdoc --no-ri --conservative"
+
+  config.vm.provider :virtualbox do |vb|
+    vb.gui = false
+    vb.customize ["modifyvm", :id, "--memory", "1024"]
+    vb.customize ["modifyvm", :id, "--cpus", "1"]
+    # This allows symlinks to be created within the /vagrant root directory, 
+    # which is something librarian-puppet needs to be able to do. This might
+    # be enabled by default depending on what version of VirtualBox is used.
+    vb.customize ["setextradata", :id, "VBoxInternal2/SharedFoldersEnableSymlinksCreate/v-root", "1"]
+  end
+  config.vm.provision :chef_solo do |chef|
+    chef.cookbooks_path = "cookbooks"
+    chef.add_recipe("apt")
+    chef.add_recipe("java")
+    chef.add_recipe("elasticsearch")
+    chef.add_recipe("git")
+    chef.add_recipe("mercurial")
+    chef.add_recipe("build-essential")
+    chef.add_recipe("golang")
+  end
+end
\ No newline at end of file
diff -ruN a/src/github.com/mattbaird/elastigo/api/baseRequest.go b/src/github.com/mattbaird/elastigo/api/baseRequest.go
--- a/src/github.com/mattbaird/elastigo/api/baseRequest.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/api/baseRequest.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,113 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+import (
+	//"bytes"
+	"encoding/json"
+	"fmt"
+	"io"
+	"log"
+	"time"
+)
+
+func DoCommand(method string, url string, data interface{}) ([]byte, error) {
+	var response map[string]interface{}
+	var body []byte
+	var httpStatusCode int
+	req, err := ElasticSearchRequest(method, url)
+	//log.Println(req.URL)
+	if err != nil {
+		return body, err
+	}
+
+	if data != nil {
+		switch v := data.(type) {
+		case string:
+			req.SetBodyString(v)
+		case io.Reader:
+			req.SetBody(v)
+		//case *bytes.Buffer:
+		//	req.SetBody(v)
+		default:
+			err = req.SetBodyJson(v)
+			if err != nil {
+				return body, err
+			}
+		}
+
+	}
+	httpStatusCode, body, err = req.Do(&response)
+
+	if err != nil {
+		return body, err
+	}
+	if httpStatusCode > 304 {
+
+		jsonErr := json.Unmarshal(body, &response)
+		if jsonErr == nil {
+			if error, ok := response["error"]; ok {
+				status, _ := response["status"]
+				return body, ESError{time.Now(), fmt.Sprintf("Error [%s] Status [%v]", error, status), httpStatusCode}
+			}
+		}
+		return body, jsonErr
+	}
+	return body, nil
+}
+
+// ESError is an error implementation that includes a time, message, and code.
+type ESError struct {
+	When time.Time
+	What string
+	Code int
+}
+
+func (e ESError) Error() string {
+	return fmt.Sprintf("%v: %v [%v]", e.When, e.What, e.Code)
+}
+
+// Exists allows the caller to check for the existance of a document using HEAD
+// This appears to be broken in the current version of elasticsearch 0.19.10, currently
+// returning nothing
+func Exists(pretty bool, index string, _type string, id string) (BaseResponse, error) {
+	var response map[string]interface{}
+	var body []byte
+	var url string
+	var retval BaseResponse
+	var httpStatusCode int
+
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/%s?%s", index, _type, id, Pretty(pretty))
+	} else {
+		url = fmt.Sprintf("/%s/%s?%s", index, id, Pretty(pretty))
+	}
+	req, err := ElasticSearchRequest("HEAD", url)
+	if err != nil {
+		// some sort of generic error handler
+	}
+	httpStatusCode, body, err = req.Do(&response)
+	if httpStatusCode > 304 {
+		if error, ok := response["error"]; ok {
+			status, _ := response["status"]
+			log.Printf("Error: %v (%v)\n", error, status)
+		}
+	} else {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			log.Println(jsonErr)
+		}
+	}
+	//fmt.Println(string(body))
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/api/baseResponse.go b/src/github.com/mattbaird/elastigo/api/baseResponse.go
--- a/src/github.com/mattbaird/elastigo/api/baseResponse.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/api/baseResponse.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,74 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+import (
+	"fmt"
+)
+
+type BaseResponse struct {
+	Ok      bool        `json:"ok"`
+	Index   string      `json:"_index,omitempty"`
+	Type    string      `json:"_type,omitempty"`
+	Id      string      `json:"_id,omitempty"`
+	Source  interface{} `json:"_source,omitempty"` // depends on the schema you've defined
+	Version int         `json:"_version,omitempty"`
+	Found   bool        `json:"found,omitempty"`
+	Exists  bool        `json:"exists,omitempty"`
+}
+type ExtendedStatus struct {
+	Ok           bool   `json:"ok"`
+	ShardsStatus Status `json:"_shards"`
+}
+type Status struct {
+	Total      int `json:"total"`
+	Successful int `json:"successful"`
+	Failed     int `json:"failed"`
+}
+
+type Match struct {
+	OK           bool         `json:"ok"`
+	Matches      []string     `json:"matches"`
+	Explaination Explaination `json:"explaination,omitempty"`
+}
+
+type Explaination struct {
+	Value       float32        `json:"value"`
+	Description string         `json:"description"`
+	Details     []Explaination `json:"details,omitempty"`
+}
+
+func Pretty(pretty bool) string {
+	prettyString := ""
+	if pretty == true {
+		prettyString = "pretty=1"
+	}
+	return prettyString
+}
+
+// http://www.elasticsearch.org/guide/reference/api/search/search-type/
+
+func Scan(scan int) string {
+	scanString := ""
+	if scan > 0 {
+		scanString = fmt.Sprintf("&search_type=scan&size=%v", scan)
+	}
+	return scanString
+}
+
+func Scroll(duration string) string {
+	scrollString := ""
+	if duration != "" {
+		scrollString = "&scroll=" + duration
+	}
+	return scrollString
+}
diff -ruN a/src/github.com/mattbaird/elastigo/api/request.go b/src/github.com/mattbaird/elastigo/api/request.go
--- a/src/github.com/mattbaird/elastigo/api/request.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/api/request.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,111 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+import (
+	"bytes"
+	"encoding/json"
+	"fmt"
+	"io"
+	"io/ioutil"
+	"log"
+	"net/http"
+	"runtime"
+	"strings"
+)
+
+type Request http.Request
+
+const (
+	Version         = "0.0.2"
+	DefaultProtocol = "http"
+	DefaultDomain   = "localhost"
+	DefaultPort     = "9200"
+)
+
+var (
+	_                        = log.Ldate
+	Protocol       string    = DefaultProtocol
+	Domain         string    = DefaultDomain
+	ClusterDomains [1]string = [1]string{DefaultDomain}
+	Port           string    = DefaultPort
+)
+
+func ElasticSearchRequest(method, path string) (*Request, error) {
+	req, err := http.NewRequest(method, fmt.Sprintf("%s://%s:%s%s", Protocol, Domain, Port, path), nil)
+	if err != nil {
+		return nil, err
+	}
+	req.Header.Add("Accept", "application/json")
+	req.Header.Add("User-Agent", "elasticSearch/"+Version+" ("+runtime.GOOS+"-"+runtime.GOARCH+")")
+	return (*Request)(req), nil
+}
+
+func (r *Request) SetBodyJson(data interface{}) error {
+	body, err := json.Marshal(data)
+	if err != nil {
+		return err
+	}
+	r.SetBody(bytes.NewReader(body))
+	r.Header.Set("Content-Type", "application/json")
+	return nil
+}
+
+func (r *Request) SetBodyString(body string) {
+	r.SetBody(strings.NewReader(body))
+}
+
+func (r *Request) SetBody(body io.Reader) {
+	rc, ok := body.(io.ReadCloser)
+	if !ok && body != nil {
+		rc = ioutil.NopCloser(body)
+	}
+	r.Body = rc
+	if body != nil {
+		switch v := body.(type) {
+		case *strings.Reader:
+			r.ContentLength = int64(v.Len())
+		case *bytes.Buffer:
+			r.ContentLength = int64(v.Len())
+		}
+	}
+}
+
+func (r *Request) Do(v interface{}) (int, []byte, error) {
+	response, bodyBytes, err := r.DoResponse(v)
+	if err != nil {
+		return -1, nil, err
+	}
+	return response.StatusCode, bodyBytes, err
+}
+
+func (r *Request) DoResponse(v interface{}) (*http.Response, []byte, error) {
+	res, err := http.DefaultClient.Do((*http.Request)(r))
+	if err != nil {
+		return nil, nil, err
+	}
+
+	defer res.Body.Close()
+	bodyBytes, err := ioutil.ReadAll(res.Body)
+
+	if err != nil {
+		return nil, nil, err
+	}
+
+	if res.StatusCode > 304 && v != nil {
+		jsonErr := json.Unmarshal(bodyBytes, v)
+		if jsonErr != nil {
+			return nil, nil, jsonErr
+		}
+	}
+	return res, bodyBytes, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/api/searchdsl.go b/src/github.com/mattbaird/elastigo/api/searchdsl.go
--- a/src/github.com/mattbaird/elastigo/api/searchdsl.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/api/searchdsl.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,31 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+type SearchRequest struct {
+	From   int    `json:"from,omitempty"`
+	Size   int    `json:"size,omitempty"`
+	Query  Query  `json:"query,omitempty"`
+	Filter Filter `json:"filter,omitempty"`
+}
+
+type Filter struct {
+	Term Term `json:"term"`
+}
+
+type Facets struct {
+	Tag Terms `json:"tag"`
+}
+
+type Terms struct {
+	Terms string `json:"terms"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/api/shared.go b/src/github.com/mattbaird/elastigo/api/shared.go
--- a/src/github.com/mattbaird/elastigo/api/shared.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/api/shared.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,24 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+type Query struct {
+	Query Term `json:"query"`
+}
+
+type Term struct {
+	Term string `json:"term"`
+}
+
+func (q Query) setQuery(query string) {
+	q.Query.Term = query
+}
diff -ruN a/src/github.com/mattbaird/elastigo/client.go b/src/github.com/mattbaird/elastigo/client.go
--- a/src/github.com/mattbaird/elastigo/client.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/client.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,81 @@
+// Copyright 2012 Matthew Baird
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+package main
+
+import (
+	"encoding/json"
+	"flag"
+	"github.com/mattbaird/elastigo/api"
+	"github.com/mattbaird/elastigo/cluster"
+	"github.com/mattbaird/elastigo/core"
+	"github.com/mattbaird/elastigo/indices"
+	"log"
+	"time"
+)
+
+var (
+	eshost *string = flag.String("host", "localhost", "Elasticsearch Server Host Address")
+)
+
+// for testing
+func main() {
+	flag.Parse()
+	log.SetFlags(log.Ltime | log.Lshortfile)
+	api.Domain = *eshost
+	response, _ := core.Index(true, "twitter", "tweet", "1", NewTweet("kimchy", "Search is cool"))
+	indices.Flush()
+	log.Printf("Index OK: %v", response.Ok)
+	searchresponse, err := core.SearchRequest(true, "twitter", "tweet", "{\"query\" : {\"term\" : { \"user\" : \"kimchy\" }}}", "", 0)
+	if err != nil {
+		log.Println("error during search:" + err.Error())
+		log.Fatal(err)
+	}
+	// try marshalling to tweet type
+	var t Tweet
+	json.Unmarshal(searchresponse.Hits.Hits[0].Source, t)
+	log.Printf("Search Found: %s", t)
+	response, _ = core.Get(true, "twitter", "tweet", "1")
+	log.Printf("Get: %v", response.Exists)
+	exists, _ := core.Exists(true, "twitter", "tweet", "1")
+	log.Printf("Exists: %v", exists)
+	indices.Flush()
+	countResponse, _ := core.Count(true, "twitter", "tweet")
+	log.Printf("Count: %v", countResponse.Count)
+	response, _ = core.Delete(true, "twitter", "tweet", "1", -1, "")
+	log.Printf("Delete OK: %v", response.Ok)
+	response, _ = core.Get(true, "twitter", "tweet", "1")
+	log.Printf("Get: %v", response.Exists)
+
+	healthResponse, _ := cluster.Health(true)
+	log.Printf("Health: %v", healthResponse.Status)
+
+	cluster.UpdateSettings("transient", "discovery.zen.minimum_master_nodes", 2)
+
+}
+
+// used in test suite, chosen to be similar to the documentation
+type Tweet struct {
+	User     string    `json:"user"`
+	PostDate time.Time `json:"postDate"`
+	Message  string    `json:"message"`
+}
+
+func NewTweet(user string, message string) Tweet {
+	return Tweet{User: user, PostDate: time.Now(), Message: message}
+}
+
+func (t *Tweet) String() string {
+	b, _ := json.Marshal(t)
+	return string(b)
+}
diff -ruN a/src/github.com/mattbaird/elastigo/cluster/clusterReroute.go b/src/github.com/mattbaird/elastigo/cluster/clusterReroute.go
--- a/src/github.com/mattbaird/elastigo/cluster/clusterReroute.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cluster/clusterReroute.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,83 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// The cluster health API allows to get a very simple status on the health of the cluster.
+// see http://www.elasticsearch.org/guide/reference/api/admin-cluster-health.html
+// TODO: implement wait_for_status, timeout, wait_for_relocating_shards, wait_for_nodes
+// TODO: implement level (Can be one of cluster, indices or shards. Controls the details level of the health
+// information returned. Defaults to cluster.)
+func Reroute(pretty bool, dryRun bool, commands Commands) (ClusterHealthResponse, error) {
+	var url string
+	var retval ClusterHealthResponse
+	if len(commands.Commands) > 0 {
+		url = fmt.Sprintf("/_cluster/reroute%s&%s", api.Pretty(pretty), dryRunOption(dryRun))
+	} else {
+		return retval, errors.New("Must pass at least one command")
+	}
+	body, err := api.DoCommand("POST", url, commands)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
+
+func dryRunOption(isDryRun bool) string {
+	if isDryRun {
+		return "dry_run"
+	}
+	return ""
+}
+
+// supported commands are
+// move (index, shard, from_node, to_node)
+// cancel (index, shard, node, allow_primary)
+// allocate (index, shard, node, allow_primary)
+
+type Commands struct {
+	Commands []interface{} `json:"commands"`
+}
+
+type MoveCommand struct {
+	Index    string `json:"index"`
+	Shard    string `json:"shard"`
+	FromNode string `json:"from_node"`
+	ToNode   string `json:"to_node"`
+}
+
+type CancelCommand struct {
+	Index        string `json:"index"`
+	Shard        string `json:"shard"`
+	Node         string `json:"node"`
+	AllowPrimary bool   `json:"allow_primary,omitempty"`
+}
+type AllocateCommand struct {
+	Index        string `json:"index"`
+	Shard        string `json:"shard"`
+	Node         string `json:"node"`
+	AllowPrimary bool   `json:"allow_primary,omitempty"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/cluster/health.go b/src/github.com/mattbaird/elastigo/cluster/health.go
--- a/src/github.com/mattbaird/elastigo/cluster/health.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cluster/health.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,107 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"net/url"
+	"strconv"
+	"strings"
+)
+
+// Health gets a very simple status on the health of the cluster. This call defaults to no parameters
+// see http://www.elasticsearch.org/guide/reference/api/admin-cluster-health.html
+func Health(pretty bool, indices ...string) (ClusterHealthResponse, error) {
+	return HealthWithParameters(pretty, "", "", "", 0, 0, indices...)
+}
+
+// HealthWithParameters gets cluster health data and exposes all parameters to the caller
+// level - one of cluster, indices, or shards
+// wait_for_status - green, yellow, or red. Will wait until the status changes to passed status
+// wait_for_relocating_shards - How many relocating shards to wait for. Default no wait
+// wait_for_nodes - The request waits until N nodes are available
+// timeout - How long to wait if any wait_* params are passed. Defaults to 30s
+func HealthWithParameters(pretty bool, level string, wait_for_status string, timeout string,
+	wait_for_relocating_shards int, wait_for_nodes int, indices ...string) (ClusterHealthResponse, error) {
+	var url string
+	var retval ClusterHealthResponse
+	url, err := getHealthUrl(pretty, level, wait_for_status, timeout, wait_for_relocating_shards, wait_for_nodes, indices...)
+	if err != nil {
+		return retval, err
+	}
+	body, err := api.DoCommand("GET", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func getHealthUrl(pretty bool, level string, wait_for_status string, timeout string,
+	wait_for_relocating_shards int, wait_for_nodes int, indices ...string) (retval string, e error) {
+	var partialURL string
+	var values url.Values = url.Values{}
+	partialURL = "/_cluster/health"
+	// If indices are specified, append them before the query params
+	if len(indices) > 0 {
+		partialURL = fmt.Sprintf("%s/%s", partialURL, strings.Join(indices, ","))
+	}
+	// level - make sure it's one of cluster, indices or shards
+	if len(level) > 0 {
+		if level != "cluster" && level != "indices" && level != "shards" {
+			return "", errors.New(fmt.Sprintf("level must be one of cluster, indices or shards. You passed %s", level))
+		}
+		values.Add("level", level)
+	}
+	// wait_for_status - make sure it's one of green, yellow, or red
+	if len(wait_for_status) > 0 {
+		if wait_for_status != "green" && wait_for_status != "yellow" && wait_for_status != "red" {
+			return "", errors.New(fmt.Sprintf("wait_for_status must be one of green, yellow, or red. You passed %s", wait_for_status))
+		}
+		values.Add("wait_for_status", wait_for_status)
+	}
+	if wait_for_relocating_shards > 0 {
+		values.Add("wait_for_relocating_shards", strconv.Itoa(wait_for_relocating_shards))
+	}
+	if wait_for_nodes > 0 {
+		values.Add("wait_for_nodes", strconv.Itoa(wait_for_nodes))
+	}
+	if len(timeout) > 0 {
+		values.Add("timeout", timeout)
+	}
+	if pretty {
+		values.Add("pretty", strconv.FormatBool(pretty))
+	}
+	return partialURL + "?" + values.Encode(), nil
+}
+
+type ClusterHealthResponse struct {
+	ClusterName         string `json:"cluster_name"`
+	Status              string `json:"status"`
+	TimedOut            bool   `json:"timed_out"`
+	NumberOfNodes       int    `json:"number_of_nodes"`
+	NumberOfDataNodes   int    `json:"number_of_data_nodes"`
+	ActivePrimaryShards int    `json:"active_primary_shards"`
+	ActiveShards        int    `json:"active_shards"`
+	RelocatingShards    int    `json:"relocating_shards"`
+	InitializingShards  int    `json:"initializing_shards"`
+	UnassignedShards    int    `json:"unassigned_shards"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/cluster/health_test.go b/src/github.com/mattbaird/elastigo/cluster/health_test.go
--- a/src/github.com/mattbaird/elastigo/cluster/health_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cluster/health_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,53 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"fmt"
+	u "github.com/araddon/gou"
+	"testing"
+)
+
+func TestUrlGeneration(t *testing.T) {
+	expectedUrl := "/_cluster/health/Indice1,Indice2,Indice3?level=cluster&pretty=true&timeout=30s&wait_for_nodes=1&wait_for_relocating_shards=1&wait_for_status=green"
+	indices := []string{"Indice1", "Indice2", "Indice3"}
+	url, err := getHealthUrl(true, "cluster", "green", "30s", 1, 1, indices...)
+	u.Assert(err == nil, t, fmt.Sprintf("err was not nil: %v", err))
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGeneration Should get %s, instead got %s", expectedUrl, url))
+}
+
+func TestUrlGenerationNoIndices(t *testing.T) {
+	expectedUrl := "/_cluster/health?level=cluster&pretty=true&timeout=30s&wait_for_nodes=1&wait_for_relocating_shards=1&wait_for_status=green"
+	indices := []string{}
+	url, err := getHealthUrl(true, "cluster", "green", "30s", 1, 1, indices...)
+	u.Assert(err == nil, t, fmt.Sprintf("err was not nil: %v", err))
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGeneration Should get %s, instead got %s", expectedUrl, url))
+}
+
+func TestUrlGenerationNoWaits(t *testing.T) {
+	expectedUrl := "/_cluster/health/Indice1,Indice2,Indice3?level=cluster&pretty=true&timeout=30s&wait_for_status=green"
+	indices := []string{"Indice1", "Indice2", "Indice3"}
+	url, err := getHealthUrl(true, "cluster", "green", "30s", 0, 0, indices...)
+	u.Assert(err == nil, t, fmt.Sprintf("err was not nil: %v", err))
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGeneration Should get %s, instead got %s", expectedUrl, url))
+}
+
+func TestUrlGenerationBadLevel(t *testing.T) {
+	indices := []string{"Indice1", "Indice2", "Indice3"}
+	_, err := getHealthUrl(true, "Level", "Wait_For_Status", "Timeout", 1, 1, indices...)
+	u.Assert(err != nil, t, fmt.Sprintf("Call should have failed with bad Level parameter: %v", err))
+}
+func TestUrlGenerationBadWaitForStatus(t *testing.T) {
+	indices := []string{"Indice1", "Indice2", "Indice3"}
+	_, err := getHealthUrl(true, "cluster", "Wait_For_Status", "Timeout", 1, 1, indices...)
+	u.Assert(err != nil, t, fmt.Sprintf("Call should have failed with bad wait_for_status parameter: %v", err))
+}
diff -ruN a/src/github.com/mattbaird/elastigo/cluster/nodesHotThreads.go b/src/github.com/mattbaird/elastigo/cluster/nodesHotThreads.go
--- a/src/github.com/mattbaird/elastigo/cluster/nodesHotThreads.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cluster/nodesHotThreads.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
diff -ruN a/src/github.com/mattbaird/elastigo/cluster/nodesInfo.go b/src/github.com/mattbaird/elastigo/cluster/nodesInfo.go
--- a/src/github.com/mattbaird/elastigo/cluster/nodesInfo.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cluster/nodesInfo.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
diff -ruN a/src/github.com/mattbaird/elastigo/cluster/nodesShutdown.go b/src/github.com/mattbaird/elastigo/cluster/nodesShutdown.go
--- a/src/github.com/mattbaird/elastigo/cluster/nodesShutdown.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cluster/nodesShutdown.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,38 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"net/url"
+	"strconv"
+	"strings"
+)
+
+// NodesShutdown allows the caller to shutdown between one and all nodes in the cluster
+// delay is a integer representing number of seconds
+// passing "" or "_all" for the nodes parameter will shut down all nodes
+// see http://www.elasticsearch.org/guide/reference/api/admin-cluster-nodes-shutdown/
+func NodesShutdown(delay int, nodes ...string) error {
+	shutdownUrl := fmt.Sprintf("/_cluster/nodes/%s/_shutdown", strings.Join(nodes, ","))
+	if delay > 0 {
+		var values url.Values = url.Values{}
+		values.Add("delay", strconv.Itoa(delay))
+		shutdownUrl += "?" + values.Encode()
+	}
+	_, err := api.DoCommand("POST", shutdownUrl, nil)
+	if err != nil {
+		return err
+	}
+	return nil
+}
diff -ruN a/src/github.com/mattbaird/elastigo/cluster/state.go b/src/github.com/mattbaird/elastigo/cluster/state.go
--- a/src/github.com/mattbaird/elastigo/cluster/state.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cluster/state.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,67 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"encoding/json"
+	"github.com/mattbaird/elastigo/api"
+	"net/url"
+	"strconv"
+	"strings"
+)
+
+// State gets the comprehensive state information for the whole cluster
+// see http://www.elasticsearch.org/guide/reference/api/admin-cluster-state/
+func State(filter_nodes bool, filter_routing_table bool, filter_metadata bool, filter_blocks bool,
+	filter_indices ...string) (ClusterStateResponse, error) {
+	url := getStateUrl(false, false, false, false, filter_indices...)
+	var retval ClusterStateResponse
+	body, err := api.DoCommand("GET", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func getStateUrl(filter_nodes bool, filter_routing_table bool, filter_metadata bool, filter_blocks bool,
+	filter_indices ...string) (retval string) {
+	var partialURL string
+	var values url.Values = url.Values{}
+	partialURL = "/_cluster/state"
+	if filter_nodes {
+		values.Add("filter_nodes", strconv.FormatBool(filter_nodes))
+	}
+	if filter_routing_table {
+		values.Add("filter_routing_table", strconv.FormatBool(filter_routing_table))
+	}
+	if filter_metadata {
+		values.Add("filter_metadata", strconv.FormatBool(filter_metadata))
+	}
+	if filter_blocks {
+		values.Add("filter_blocks", strconv.FormatBool(filter_blocks))
+	}
+	if len(filter_indices) > 0 {
+		values.Add("filter_indices", strings.Join(filter_indices, ","))
+	}
+
+	return partialURL + "?" + values.Encode()
+}
+
+type ClusterStateResponse struct {
+}
diff -ruN a/src/github.com/mattbaird/elastigo/cluster/updateSettings.go b/src/github.com/mattbaird/elastigo/cluster/updateSettings.go
--- a/src/github.com/mattbaird/elastigo/cluster/updateSettings.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cluster/updateSettings.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,48 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// UpdateSettings allows to update cluster wide specific settings. Defaults to Transient setting
+// Settings updated can either be persistent (applied cross restarts) or transient (will not survive a full cluster restart).
+// http://www.elasticsearch.org/guide/reference/api/admin-cluster-update-settings.html
+func UpdateSettings(settingType string, key string, value int) (ClusterSettingsResponse, error) {
+	var retval ClusterSettingsResponse
+	if settingType != "transient" && settingType != "persistent" {
+		return retval, errors.New(fmt.Sprintf("settingType must be one of transient or persistent, you passed %s", settingType))
+	}
+	var url string = "/_cluster/state"
+	m := map[string]map[string]int{settingType: map[string]int{key: value}}
+	body, err := api.DoCommand("PUT", url, m)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type ClusterSettingsResponse struct {
+	Transient  map[string]int `json:"transient"`
+	Persistent map[string]int `json:"persistent"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/CHANGELOG.md b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/CHANGELOG.md
--- a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/CHANGELOG.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/CHANGELOG.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,15 @@
+## v1.1.2:
+
+* [COOK-1620] - support OS X 10.8
+
+## v1.1.0:
+
+* [COOK-1098] - support amazon linux
+* [COOK-1149] - support Mac OS X
+* [COOK-1296] - allow for compile-time installation of packages
+  through an attribute (see README)
+
+## v1.0.2:
+
+* [COOK-1098] - Add Amazon Linux platform support
+* [COOK-1149] - Add OS X platform support
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/CONTRIBUTING b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/CONTRIBUTING
--- a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/CONTRIBUTING	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/CONTRIBUTING	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,29 @@
+If you would like to contribute, please open a ticket in JIRA:
+
+* http://tickets.opscode.com
+
+Create the ticket in the COOK project and use the cookbook name as the
+component.
+
+For all code contributions, we ask that contributors sign a
+contributor license agreement (CLA). Instructions may be found here:
+
+* http://wiki.opscode.com/display/chef/How+to+Contribute
+
+When contributing changes to individual cookbooks, please do not
+modify the version number in the metadata.rb. Also please do not
+update the CHANGELOG.md for a new version. Not all changes to a
+cookbook may be merged and released in the same versions. Opscode will
+handle the version updates during the release process. You are welcome
+to correct typos or otherwise make updates to documentation in the
+README.
+
+If a contribution adds new platforms or platform versions, indicate
+such in the body of the commit message(s), and update the relevant
+COOK ticket. When writing commit messages, it is helpful for others if
+you indicate the COOK ticket. For example:
+
+    git commit -m '[COOK-1041] Updated pool resource to correctly delete.'
+
+In the ticket itself, it is also helpful if you include log output of
+a successful Chef run, but this is not absolutely required.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/LICENSE b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/LICENSE
--- a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/LICENSE	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,201 @@
+                              Apache License
+                        Version 2.0, January 2004
+                     http://www.apache.org/licenses/
+
+TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+1. Definitions.
+
+   "License" shall mean the terms and conditions for use, reproduction,
+   and distribution as defined by Sections 1 through 9 of this document.
+
+   "Licensor" shall mean the copyright owner or entity authorized by
+   the copyright owner that is granting the License.
+
+   "Legal Entity" shall mean the union of the acting entity and all
+   other entities that control, are controlled by, or are under common
+   control with that entity. For the purposes of this definition,
+   "control" means (i) the power, direct or indirect, to cause the
+   direction or management of such entity, whether by contract or
+   otherwise, or (ii) ownership of fifty percent (50%) or more of the
+   outstanding shares, or (iii) beneficial ownership of such entity.
+
+   "You" (or "Your") shall mean an individual or Legal Entity
+   exercising permissions granted by this License.
+
+   "Source" form shall mean the preferred form for making modifications,
+   including but not limited to software source code, documentation
+   source, and configuration files.
+
+   "Object" form shall mean any form resulting from mechanical
+   transformation or translation of a Source form, including but
+   not limited to compiled object code, generated documentation,
+   and conversions to other media types.
+
+   "Work" shall mean the work of authorship, whether in Source or
+   Object form, made available under the License, as indicated by a
+   copyright notice that is included in or attached to the work
+   (an example is provided in the Appendix below).
+
+   "Derivative Works" shall mean any work, whether in Source or Object
+   form, that is based on (or derived from) the Work and for which the
+   editorial revisions, annotations, elaborations, or other modifications
+   represent, as a whole, an original work of authorship. For the purposes
+   of this License, Derivative Works shall not include works that remain
+   separable from, or merely link (or bind by name) to the interfaces of,
+   the Work and Derivative Works thereof.
+
+   "Contribution" shall mean any work of authorship, including
+   the original version of the Work and any modifications or additions
+   to that Work or Derivative Works thereof, that is intentionally
+   submitted to Licensor for inclusion in the Work by the copyright owner
+   or by an individual or Legal Entity authorized to submit on behalf of
+   the copyright owner. For the purposes of this definition, "submitted"
+   means any form of electronic, verbal, or written communication sent
+   to the Licensor or its representatives, including but not limited to
+   communication on electronic mailing lists, source code control systems,
+   and issue tracking systems that are managed by, or on behalf of, the
+   Licensor for the purpose of discussing and improving the Work, but
+   excluding communication that is conspicuously marked or otherwise
+   designated in writing by the copyright owner as "Not a Contribution."
+
+   "Contributor" shall mean Licensor and any individual or Legal Entity
+   on behalf of whom a Contribution has been received by Licensor and
+   subsequently incorporated within the Work.
+
+2. Grant of Copyright License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   copyright license to reproduce, prepare Derivative Works of,
+   publicly display, publicly perform, sublicense, and distribute the
+   Work and such Derivative Works in Source or Object form.
+
+3. Grant of Patent License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   (except as stated in this section) patent license to make, have made,
+   use, offer to sell, sell, import, and otherwise transfer the Work,
+   where such license applies only to those patent claims licensable
+   by such Contributor that are necessarily infringed by their
+   Contribution(s) alone or by combination of their Contribution(s)
+   with the Work to which such Contribution(s) was submitted. If You
+   institute patent litigation against any entity (including a
+   cross-claim or counterclaim in a lawsuit) alleging that the Work
+   or a Contribution incorporated within the Work constitutes direct
+   or contributory patent infringement, then any patent licenses
+   granted to You under this License for that Work shall terminate
+   as of the date such litigation is filed.
+
+4. Redistribution. You may reproduce and distribute copies of the
+   Work or Derivative Works thereof in any medium, with or without
+   modifications, and in Source or Object form, provided that You
+   meet the following conditions:
+
+   (a) You must give any other recipients of the Work or
+       Derivative Works a copy of this License; and
+
+   (b) You must cause any modified files to carry prominent notices
+       stating that You changed the files; and
+
+   (c) You must retain, in the Source form of any Derivative Works
+       that You distribute, all copyright, patent, trademark, and
+       attribution notices from the Source form of the Work,
+       excluding those notices that do not pertain to any part of
+       the Derivative Works; and
+
+   (d) If the Work includes a "NOTICE" text file as part of its
+       distribution, then any Derivative Works that You distribute must
+       include a readable copy of the attribution notices contained
+       within such NOTICE file, excluding those notices that do not
+       pertain to any part of the Derivative Works, in at least one
+       of the following places: within a NOTICE text file distributed
+       as part of the Derivative Works; within the Source form or
+       documentation, if provided along with the Derivative Works; or,
+       within a display generated by the Derivative Works, if and
+       wherever such third-party notices normally appear. The contents
+       of the NOTICE file are for informational purposes only and
+       do not modify the License. You may add Your own attribution
+       notices within Derivative Works that You distribute, alongside
+       or as an addendum to the NOTICE text from the Work, provided
+       that such additional attribution notices cannot be construed
+       as modifying the License.
+
+   You may add Your own copyright statement to Your modifications and
+   may provide additional or different license terms and conditions
+   for use, reproduction, or distribution of Your modifications, or
+   for any such Derivative Works as a whole, provided Your use,
+   reproduction, and distribution of the Work otherwise complies with
+   the conditions stated in this License.
+
+5. Submission of Contributions. Unless You explicitly state otherwise,
+   any Contribution intentionally submitted for inclusion in the Work
+   by You to the Licensor shall be under the terms and conditions of
+   this License, without any additional terms or conditions.
+   Notwithstanding the above, nothing herein shall supersede or modify
+   the terms of any separate license agreement you may have executed
+   with Licensor regarding such Contributions.
+
+6. Trademarks. This License does not grant permission to use the trade
+   names, trademarks, service marks, or product names of the Licensor,
+   except as required for reasonable and customary use in describing the
+   origin of the Work and reproducing the content of the NOTICE file.
+
+7. Disclaimer of Warranty. Unless required by applicable law or
+   agreed to in writing, Licensor provides the Work (and each
+   Contributor provides its Contributions) on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+   implied, including, without limitation, any warranties or conditions
+   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+   PARTICULAR PURPOSE. You are solely responsible for determining the
+   appropriateness of using or redistributing the Work and assume any
+   risks associated with Your exercise of permissions under this License.
+
+8. Limitation of Liability. In no event and under no legal theory,
+   whether in tort (including negligence), contract, or otherwise,
+   unless required by applicable law (such as deliberate and grossly
+   negligent acts) or agreed to in writing, shall any Contributor be
+   liable to You for damages, including any direct, indirect, special,
+   incidental, or consequential damages of any character arising as a
+   result of this License or out of the use or inability to use the
+   Work (including but not limited to damages for loss of goodwill,
+   work stoppage, computer failure or malfunction, or any and all
+   other commercial damages or losses), even if such Contributor
+   has been advised of the possibility of such damages.
+
+9. Accepting Warranty or Additional Liability. While redistributing
+   the Work or Derivative Works thereof, You may choose to offer,
+   and charge a fee for, acceptance of support, warranty, indemnity,
+   or other liability obligations and/or rights consistent with this
+   License. However, in accepting such obligations, You may act only
+   on Your own behalf and on Your sole responsibility, not on behalf
+   of any other Contributor, and only if You agree to indemnify,
+   defend, and hold each Contributor harmless for any liability
+   incurred by, or claims asserted against, such Contributor by reason
+   of your accepting any such warranty or additional liability.
+
+END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+   To apply the Apache License to your work, attach the following
+   boilerplate notice, with the fields enclosed by brackets "[]"
+   replaced with your own identifying information. (Don't include
+   the brackets!)  The text should be enclosed in the appropriate
+   comment syntax for the file format. We also recommend that a
+   file or class name and description of purpose be included on the
+   same "printed page" as the copyright notice for easier
+   identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/README.md b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/README.md
--- a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/README.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,124 @@
+Description
+===========
+
+Installs packages required for compiling C software from source. Use
+this cookbook if you wish to compile C programs, or install RubyGems
+with native extensions.
+
+Requirements
+============
+
+## Platform
+
+Supported platforms by platform family:
+
+* Linux (debian, rhel, fedora)
+* Darwin (`mac_os_x` 10.6+)
+
+Attributes
+==========
+
+* `node['build_essential']['compiletime']` - Whether the resources in
+the default recipe should be configured at the "Compile" phase of the
+Chef run. Defaults to false, see __Usage__ for more information.
+* `node['build_essential']['osx']['gcc_installer_url']` - The URL of
+  the OS X GCC package installer (.pkg).
+* `node['build_essential']['osx']['gcc_installer_checksum']` - The
+  SHA256 checksum of the OS X GCC installer.
+
+Recipes
+=======
+
+This cookbook has one recipe, default.
+
+On Linux platforms (see __Platform__ above for a supported list of
+families), packages required to build C source projects are installed.
+This includes GCC, make, autconf and others. On Debian-family
+distributions, the apt-cache may need to be updated, especially during
+compile time installation. See __Usage__ for further information.
+
+On Mac OS X, the GCC standalone installer by Kenneth Reitz is
+installed. Note that this is *not* the Xcode CLI package, as that does
+not include all programs and headers required to build some common
+GNU-style C projects, such as those that are available from projects
+such as MacPorts or Homebrew. Changing the attributes for the GCC
+installer URL and checksum to the Xcode values may work, but this is
+untested.
+
+Usage
+=====
+
+Simply include the `build-essential` and the required tools will be
+installed to the system, and later recipes will be able to compile
+software from C source code.
+
+For RubyGems that include native C extensions you wish to use with
+Chef, you should do two things.
+
+0. Ensure that the C libraries, include files and other assorted "dev"
+type packages are installed. You should do this in the compile phase
+after the build-essential recipe.
+1. Use the `chef_gem` resource in your recipes. This requires Chef version 0.10.10+.
+2. Set the `compiletime` attribute in roles where such recipes are
+required. This will ensure that the build tools are available to
+compile the RubyGems' extensions, as `chef_gem` happens during the
+compile phase, too.
+
+Example installation of a devel package at compile-time in a recipe:
+
+    package "mypackage-dev" do
+      action :nothing
+    end.run_action(:install)
+
+Example use of `chef_gem`:
+
+    chef_gem "mygem"
+
+Example role:
+
+    name "myapp"
+    run_list(
+      "recipe[build-essential]",
+      "recipe[myapp]"
+    )
+    default_attributes(
+      "build_essential" => {
+        "compiletime" => true
+      }
+    )
+
+The compile time option (via the attribute) is to ensure that the
+proper packages are available at the right time in the Chef run. It is
+recommended that the build-essential recipe appear early in the run
+list.
+
+The Chef wiki has documentation on
+[the anatomy of a chef run](http://wiki.opscode.com/display/chef/Anatomy+of+a+Chef+Run).
+
+Limitations
+===========
+
+It is not in the scope of this cookbook to handle installing the
+required headers for individual software projects in order to compile
+them, or to compile RubyGems with native C extensions. You should
+create a cookbook for handling that.
+
+License and Author
+==================
+
+Author:: Joshua Timberman (<joshua@opscode.com>)
+Author:: Seth Chisamore (<schisamo@opscode.com>)
+
+Copyright 2009-2011, Opscode, Inc. (<legal@opscode.com>)
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/attributes/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/attributes/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/attributes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/attributes/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,33 @@
+#
+# Cookbook Name:: build-essential
+# Attributes:: default
+#
+# Copyright 2008-2012, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+default['build_essential']['compiletime'] = false
+
+case platform
+when "mac_os_x"
+  case
+  when Chef::VersionConstraint.new("~> 10.7.0").include?(platform_version),
+       Chef::VersionConstraint.new("~> 10.8.0").include?(platform_version)
+    default['build_essential']['osx']['gcc_installer_url'] = "https://github.com/downloads/kennethreitz/osx-gcc-installer/GCC-10.7-v2.pkg"
+    default['build_essential']['osx']['gcc_installer_checksum'] = "df36aa87606feb99d0db9ac9a492819e"
+  when Chef::VersionConstraint.new("~> 10.6.0").include?(platform_version)
+    default['build_essential']['osx']['gcc_installer_url'] = "https://github.com/downloads/kennethreitz/osx-gcc-installer/GCC-10.6.pkg"
+    default['build_essential']['osx']['gcc_installer_checksum'] = "d1db5bab6a3f6b9f3b5577a130baeefa"
+  end
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/metadata.rb b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/metadata.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/metadata.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/metadata.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+maintainer        "Opscode, Inc."
+maintainer_email  "cookbooks@opscode.com"
+license           "Apache 2.0"
+description       "Installs C compiler / build tools"
+version           "1.1.2"
+recipe            "build-essential", "Installs packages required for compiling C software from source."
+
+%w{ fedora redhat centos ubuntu debian amazon }.each do |os|
+  supports os
+end
+
+supports "mac_os_x", ">= 10.6.0"
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/recipes/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/recipes/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/build-essential/recipes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/build-essential/recipes/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,79 @@
+#
+# Cookbook Name:: build-essential
+# Recipe:: default
+#
+# Copyright 2008-2009, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+require 'chef/shell_out'
+
+compiletime = node['build_essential']['compiletime']
+
+case node['os']
+when "linux"
+
+  # on apt-based platforms when first provisioning we need to force
+  # apt-get update at compiletime if we are going to try to install at compiletime
+  if node['platform_family'] == "debian"
+    execute "apt-get update" do
+      action :nothing
+      # tip: to suppress this running every time, just use the apt cookbook
+      not_if do
+        ::File.exists?('/var/lib/apt/periodic/update-success-stamp') &&
+        ::File.mtime('/var/lib/apt/periodic/update-success-stamp') > Time.now - 86400*2
+      end
+    end.run_action(:run) if compiletime
+  end
+
+  packages = case node['platform_family']
+    when "debian"
+      %w{build-essential binutils-doc}
+    when "rhel", "fedora"
+      %w{gcc gcc-c++ kernel-devel make}
+    end
+
+  packages.each do |pkg|
+    r = package pkg do
+      action ( compiletime ? :nothing : :install )
+    end
+    r.run_action(:install) if compiletime
+  end
+
+  %w{autoconf flex bison}.each do |pkg|
+    r = package pkg do
+      action ( compiletime ? :nothing : :install )
+    end
+    r.run_action(:install) if compiletime
+  end
+when "darwin"
+  result = Chef::ShellOut.new("pkgutil --pkgs").run_command
+  installed = result.stdout.split("\n").include?("com.apple.pkg.gcc4.2Leo")
+  pkg_filename = File.basename(node['build_essential']['osx']['gcc_installer_url'])
+  pkg_path = "#{Chef::Config[:file_cache_path]}/#{pkg_filename}"
+
+  r = remote_file pkg_path do
+    source node['build_essential']['osx']['gcc_installer_url']
+    checksum node['build_essential']['osx']['gcc_installer_checksum']
+    action ( compiletime ? :nothing : :create )
+    not_if { installed }
+  end
+  r.run_action(:create) if compiletime
+
+  r = execute "sudo installer -pkg \"#{pkg_path}\" -target /" do
+    action ( compiletime ? :nothing : :run )
+    not_if { installed }
+  end
+  r.run_action(:run) if compiletime
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/CHANGELOG.md b/src/github.com/mattbaird/elastigo/cookbooks/git/CHANGELOG.md
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/CHANGELOG.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/CHANGELOG.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,16 @@
+## v1.0.2:
+
+* [COOK-1537] - add recipe for source installation
+
+## v1.0.0:
+
+* [COOK-1152] - Add support for Mac OS X
+* [COOK-1112] - Add support for Windows
+
+## v0.10.0:
+
+* [COOK-853] - Git client installation on CentOS
+
+## v0.9.0:
+
+* Current public release.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/CONTRIBUTING b/src/github.com/mattbaird/elastigo/cookbooks/git/CONTRIBUTING
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/CONTRIBUTING	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/CONTRIBUTING	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,29 @@
+If you would like to contribute, please open a ticket in JIRA:
+
+* http://tickets.opscode.com
+
+Create the ticket in the COOK project and use the cookbook name as the
+component.
+
+For all code contributions, we ask that contributors sign a
+contributor license agreement (CLA). Instructions may be found here:
+
+* http://wiki.opscode.com/display/chef/How+to+Contribute
+
+When contributing changes to individual cookbooks, please do not
+modify the version number in the metadata.rb. Also please do not
+update the CHANGELOG.md for a new version. Not all changes to a
+cookbook may be merged and released in the same versions. Opscode will
+handle the version updates during the release process. You are welcome
+to correct typos or otherwise make updates to documentation in the
+README.
+
+If a contribution adds new platforms or platform versions, indicate
+such in the body of the commit message(s), and update the relevant
+COOK ticket. When writing commit messages, it is helpful for others if
+you indicate the COOK ticket. For example:
+
+    git commit -m '[COOK-1041] Updated pool resource to correctly delete.'
+
+In the ticket itself, it is also helpful if you include log output of
+a successful Chef run, but this is not absolutely required.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/LICENSE b/src/github.com/mattbaird/elastigo/cookbooks/git/LICENSE
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/LICENSE	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,201 @@
+                              Apache License
+                        Version 2.0, January 2004
+                     http://www.apache.org/licenses/
+
+TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+1. Definitions.
+
+   "License" shall mean the terms and conditions for use, reproduction,
+   and distribution as defined by Sections 1 through 9 of this document.
+
+   "Licensor" shall mean the copyright owner or entity authorized by
+   the copyright owner that is granting the License.
+
+   "Legal Entity" shall mean the union of the acting entity and all
+   other entities that control, are controlled by, or are under common
+   control with that entity. For the purposes of this definition,
+   "control" means (i) the power, direct or indirect, to cause the
+   direction or management of such entity, whether by contract or
+   otherwise, or (ii) ownership of fifty percent (50%) or more of the
+   outstanding shares, or (iii) beneficial ownership of such entity.
+
+   "You" (or "Your") shall mean an individual or Legal Entity
+   exercising permissions granted by this License.
+
+   "Source" form shall mean the preferred form for making modifications,
+   including but not limited to software source code, documentation
+   source, and configuration files.
+
+   "Object" form shall mean any form resulting from mechanical
+   transformation or translation of a Source form, including but
+   not limited to compiled object code, generated documentation,
+   and conversions to other media types.
+
+   "Work" shall mean the work of authorship, whether in Source or
+   Object form, made available under the License, as indicated by a
+   copyright notice that is included in or attached to the work
+   (an example is provided in the Appendix below).
+
+   "Derivative Works" shall mean any work, whether in Source or Object
+   form, that is based on (or derived from) the Work and for which the
+   editorial revisions, annotations, elaborations, or other modifications
+   represent, as a whole, an original work of authorship. For the purposes
+   of this License, Derivative Works shall not include works that remain
+   separable from, or merely link (or bind by name) to the interfaces of,
+   the Work and Derivative Works thereof.
+
+   "Contribution" shall mean any work of authorship, including
+   the original version of the Work and any modifications or additions
+   to that Work or Derivative Works thereof, that is intentionally
+   submitted to Licensor for inclusion in the Work by the copyright owner
+   or by an individual or Legal Entity authorized to submit on behalf of
+   the copyright owner. For the purposes of this definition, "submitted"
+   means any form of electronic, verbal, or written communication sent
+   to the Licensor or its representatives, including but not limited to
+   communication on electronic mailing lists, source code control systems,
+   and issue tracking systems that are managed by, or on behalf of, the
+   Licensor for the purpose of discussing and improving the Work, but
+   excluding communication that is conspicuously marked or otherwise
+   designated in writing by the copyright owner as "Not a Contribution."
+
+   "Contributor" shall mean Licensor and any individual or Legal Entity
+   on behalf of whom a Contribution has been received by Licensor and
+   subsequently incorporated within the Work.
+
+2. Grant of Copyright License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   copyright license to reproduce, prepare Derivative Works of,
+   publicly display, publicly perform, sublicense, and distribute the
+   Work and such Derivative Works in Source or Object form.
+
+3. Grant of Patent License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   (except as stated in this section) patent license to make, have made,
+   use, offer to sell, sell, import, and otherwise transfer the Work,
+   where such license applies only to those patent claims licensable
+   by such Contributor that are necessarily infringed by their
+   Contribution(s) alone or by combination of their Contribution(s)
+   with the Work to which such Contribution(s) was submitted. If You
+   institute patent litigation against any entity (including a
+   cross-claim or counterclaim in a lawsuit) alleging that the Work
+   or a Contribution incorporated within the Work constitutes direct
+   or contributory patent infringement, then any patent licenses
+   granted to You under this License for that Work shall terminate
+   as of the date such litigation is filed.
+
+4. Redistribution. You may reproduce and distribute copies of the
+   Work or Derivative Works thereof in any medium, with or without
+   modifications, and in Source or Object form, provided that You
+   meet the following conditions:
+
+   (a) You must give any other recipients of the Work or
+       Derivative Works a copy of this License; and
+
+   (b) You must cause any modified files to carry prominent notices
+       stating that You changed the files; and
+
+   (c) You must retain, in the Source form of any Derivative Works
+       that You distribute, all copyright, patent, trademark, and
+       attribution notices from the Source form of the Work,
+       excluding those notices that do not pertain to any part of
+       the Derivative Works; and
+
+   (d) If the Work includes a "NOTICE" text file as part of its
+       distribution, then any Derivative Works that You distribute must
+       include a readable copy of the attribution notices contained
+       within such NOTICE file, excluding those notices that do not
+       pertain to any part of the Derivative Works, in at least one
+       of the following places: within a NOTICE text file distributed
+       as part of the Derivative Works; within the Source form or
+       documentation, if provided along with the Derivative Works; or,
+       within a display generated by the Derivative Works, if and
+       wherever such third-party notices normally appear. The contents
+       of the NOTICE file are for informational purposes only and
+       do not modify the License. You may add Your own attribution
+       notices within Derivative Works that You distribute, alongside
+       or as an addendum to the NOTICE text from the Work, provided
+       that such additional attribution notices cannot be construed
+       as modifying the License.
+
+   You may add Your own copyright statement to Your modifications and
+   may provide additional or different license terms and conditions
+   for use, reproduction, or distribution of Your modifications, or
+   for any such Derivative Works as a whole, provided Your use,
+   reproduction, and distribution of the Work otherwise complies with
+   the conditions stated in this License.
+
+5. Submission of Contributions. Unless You explicitly state otherwise,
+   any Contribution intentionally submitted for inclusion in the Work
+   by You to the Licensor shall be under the terms and conditions of
+   this License, without any additional terms or conditions.
+   Notwithstanding the above, nothing herein shall supersede or modify
+   the terms of any separate license agreement you may have executed
+   with Licensor regarding such Contributions.
+
+6. Trademarks. This License does not grant permission to use the trade
+   names, trademarks, service marks, or product names of the Licensor,
+   except as required for reasonable and customary use in describing the
+   origin of the Work and reproducing the content of the NOTICE file.
+
+7. Disclaimer of Warranty. Unless required by applicable law or
+   agreed to in writing, Licensor provides the Work (and each
+   Contributor provides its Contributions) on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+   implied, including, without limitation, any warranties or conditions
+   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+   PARTICULAR PURPOSE. You are solely responsible for determining the
+   appropriateness of using or redistributing the Work and assume any
+   risks associated with Your exercise of permissions under this License.
+
+8. Limitation of Liability. In no event and under no legal theory,
+   whether in tort (including negligence), contract, or otherwise,
+   unless required by applicable law (such as deliberate and grossly
+   negligent acts) or agreed to in writing, shall any Contributor be
+   liable to You for damages, including any direct, indirect, special,
+   incidental, or consequential damages of any character arising as a
+   result of this License or out of the use or inability to use the
+   Work (including but not limited to damages for loss of goodwill,
+   work stoppage, computer failure or malfunction, or any and all
+   other commercial damages or losses), even if such Contributor
+   has been advised of the possibility of such damages.
+
+9. Accepting Warranty or Additional Liability. While redistributing
+   the Work or Derivative Works thereof, You may choose to offer,
+   and charge a fee for, acceptance of support, warranty, indemnity,
+   or other liability obligations and/or rights consistent with this
+   License. However, in accepting such obligations, You may act only
+   on Your own behalf and on Your sole responsibility, not on behalf
+   of any other Contributor, and only if You agree to indemnify,
+   defend, and hold each Contributor harmless for any liability
+   incurred by, or claims asserted against, such Contributor by reason
+   of your accepting any such warranty or additional liability.
+
+END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+   To apply the Apache License to your work, attach the following
+   boilerplate notice, with the fields enclosed by brackets "[]"
+   replaced with your own identifying information. (Don't include
+   the brackets!)  The text should be enclosed in the appropriate
+   comment syntax for the file format. We also recommend that a
+   file or class name and description of purpose be included on the
+   same "printed page" as the copyright notice for easier
+   identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/README.md b/src/github.com/mattbaird/elastigo/cookbooks/git/README.md
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/README.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,62 @@
+Description
+===========
+
+Installs git and optionally sets up a git server as a daemon under runit.
+
+Requirements
+============
+
+## Platform:
+
+* Debian/Ubuntu
+* ArchLinux
+
+## Cookbooks:
+
+* runit
+
+Recipes
+=======
+
+## default
+
+Installs base git packages based on platform.
+
+## server
+
+Sets up a git daemon to provide a server.
+
+## source
+
+Installs git from source.
+
+Usage
+=====
+
+This cookbook primarily installs git core packages. It can also be
+used to serve git repositories.
+
+    include_recipe "git::server"
+
+This creates the directory /srv/git and starts a git daemon, exporting
+all repositories found. Repositories need to be added manually, but
+will be available once they are created.
+
+License and Author
+==================
+
+Author:: Joshua Timberman (<joshua@opscode.com>)
+
+Copyright:: 2009-2012, Opscode, Inc.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/attributes/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/git/attributes/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/attributes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/attributes/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,36 @@
+#
+# Author:: Jamie Winsor (<jamie@vialstudios.com>)
+# Cookbook Name:: git
+# Attributes:: default
+#
+# Copyright 2008-2012, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+case platform_family 
+when 'windows'
+  set[:git][:version] = "1.7.9-preview20120201"
+  set[:git][:url] = "http://msysgit.googlecode.com/files/Git-#{node[:git][:version]}.exe"
+  set[:git][:checksum] = "0627394709375140d1e54e923983d259a60f9d8e"
+when "mac_os_x"
+  default[:git][:osx_dmg][:app_name]    = "git-1.7.9.4-intel-universal-snow-leopard"
+  default[:git][:osx_dmg][:volumes_dir] = "Git 1.7.9.4 Snow Leopard Intel Universal"
+  default[:git][:osx_dmg][:package_id]  = "GitOSX.Installer.git1794.git.pkg"
+  default[:git][:osx_dmg][:url]         = "http://git-osx-installer.googlecode.com/files/git-1.7.9.4-intel-universal-snow-leopard.dmg"
+  default[:git][:osx_dmg][:checksum]    = "661c3fcf765572d3978df17c7636d59e"
+else
+  default[:git][:prefix] = "/usr/local"
+  default[:git][:version] = "1.7.11.4"
+  default[:git][:url] = "https://github.com/git/git/tarball/v#{node[:git][:version]}"
+  default[:git][:checksum] = "7a26d9bd0fd3384374bdc1afaae829f406bc123126817d994a460c49a3260ecc"
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/metadata.rb b/src/github.com/mattbaird/elastigo/cookbooks/git/metadata.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/metadata.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/metadata.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,19 @@
+maintainer        "Opscode, Inc."
+maintainer_email  "cookbooks@opscode.com"
+license           "Apache 2.0"
+description       "Installs git and/or sets up a Git server daemon"
+long_description  IO.read(File.join(File.dirname(__FILE__), 'README.md'))
+version           "1.0.2"
+recipe            "git", "Installs git"
+recipe            "git::server", "Sets up a runit_service for git daemon"
+recipe            "git::source", "Installs git from source"
+
+%w{ amazon arch centos debian fedora redhat scientific ubuntu windows }.each do |os|
+  supports os
+end
+
+supports "mac_os_x", ">= 10.6.0"
+
+%w{ build-essential dmg runit yum }.each do |cb|
+  depends cb
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,47 @@
+#
+# Cookbook Name:: git
+# Recipe:: default
+#
+# Copyright 2008-2009, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+case node[:platform]
+when "debian", "ubuntu"
+  package "git-core"
+when "centos","redhat","scientific","fedora"
+  case node[:platform_version].to_i
+  when 5
+    include_recipe "yum::epel"
+  end
+  package "git"
+when "windows"
+  windows_package "git" do
+    source node[:git][:url]
+    checksum node[:git][:checksum]
+    action :install
+    not_if { File.exists? 'C:\Program Files (x86)\Git\bin\git.exe' }
+  end
+when "mac_os_x"
+  dmg_package "GitOSX-Installer" do
+    app node[:git][:osx_dmg][:app_name]
+    package_id node[:git][:osx_dmg][:package_id]
+    volumes_dir node[:git][:osx_dmg][:volumes_dir]
+    source node[:git][:osx_dmg][:url]
+    checksum node[:git][:osx_dmg][:checksum]
+    type "pkg"
+    action :install
+  end
+else
+  package "git"
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/server.rb b/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/server.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/server.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/server.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,34 @@
+#
+# Cookbook Name:: git
+# Recipe:: server
+#
+# Copyright 2009, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+include_recipe "git"
+
+directory "/srv/git" do
+  owner "root"
+  group "root"
+  mode 0755
+end
+
+case node[:platform]
+when "debian", "ubuntu"
+  include_recipe "runit"
+  runit_service "git-daemon"
+else
+  log "Platform requires setting up a git daemon service script."
+  log "Hint: /usr/bin/git daemon --export-all --user=nobody --group=daemon --base-path=/srv/git"
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/source.rb b/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/source.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/source.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/recipes/source.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,44 @@
+#
+# Cookbook Name:: git
+# Recipe:: source
+#
+# Copyright 2012, Brian Flad, Fletcher Nichol
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+include_recipe "build-essential"
+
+pkgs = value_for_platform_family(
+  ["rhel"] => %w{ expat-devel gettext-devel libcurl-devel openssl-devel zlib-devel }
+)
+
+pkgs.each do |pkg|
+  package pkg
+end
+
+remote_file "#{Chef::Config[:file_cache_path]}/git-#{node[:git][:version]}.tar.gz" do
+  source    node[:git][:url]
+  checksum  node[:git][:checksum]
+  mode      "0644"
+  not_if "test -f #{Chef::Config[:file_cache_path]}/git-#{node[:git][:version]}.tar.gz"
+end
+
+execute "Extracting and Building Git #{node[:git][:version]} from Source" do
+  cwd Chef::Config[:file_cache_path]
+  command <<-COMMAND
+    (mkdir git-#{node[:git][:version]} && tar -zxf git-#{node[:git][:version]}.tar.gz -C git-#{node[:git][:version]} --strip-components 1)
+    (cd git-#{node[:git][:version]} && make prefix=#{node[:git][:prefix]} install)
+  COMMAND
+  creates "node[:git][:prefix]}/bin/git"
+  not_if "git --version | grep #{node[:git][:version]}"
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/templates/default/sv-git-daemon-log-run.erb b/src/github.com/mattbaird/elastigo/cookbooks/git/templates/default/sv-git-daemon-log-run.erb
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/templates/default/sv-git-daemon-log-run.erb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/templates/default/sv-git-daemon-log-run.erb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,2 @@
+#!/bin/sh
+exec svlogd -tt ./main
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/git/templates/default/sv-git-daemon-run.erb b/src/github.com/mattbaird/elastigo/cookbooks/git/templates/default/sv-git-daemon-run.erb
--- a/src/github.com/mattbaird/elastigo/cookbooks/git/templates/default/sv-git-daemon-run.erb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/git/templates/default/sv-git-daemon-run.erb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,3 @@
+#!/bin/sh
+exec 2>&1
+exec /usr/bin/git daemon --export-all --user=nobody --group=daemon --base-path=/srv/git /srv/git 
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/golang/README.md b/src/github.com/mattbaird/elastigo/cookbooks/golang/README.md
--- a/src/github.com/mattbaird/elastigo/cookbooks/golang/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/golang/README.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,29 @@
+# Go Language Chef Cookbook
+
+This is an OpsCode Chef cookbook for [Go, the programming language](http://golang.org).
+
+It uses the ["Todd Vierling" Ubuntu PPA](https://launchpad.net/~duh/+archive/golang)
+and allows you to tweak version using Chef node attributes.
+
+It is released under the [Apache Public License 2.0](http://www.apache.org/licenses/LICENSE-2.0.html).
+
+
+## Recipes
+
+Main recipe is `golang::default`.
+
+## Supported OSes
+
+Ubuntu 10.10 to 12.04, will likely work just as well on Debian unstable.
+
+
+## Dependencies
+
+None.
+
+
+## Copyright & License
+
+Matthew Baird, 2013.
+
+Released under the [Apache Public License 2.0](http://www.apache.org/licenses/LICENSE-2.0.html).
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/golang/attributes/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/golang/attributes/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/golang/attributes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/golang/attributes/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,11 @@
+default[:golang] = {
+  # can be "stable" or "tip"
+  :version => "stable",
+  :multi => {
+    :versions => %w(go1.0.3 go1.1.1),
+    :default_version  => "go1.1.1",
+    :aliases => {
+      "go1" => "go1.1.1"
+    }
+  }
+}
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/golang/metadata.rb b/src/github.com/mattbaird/elastigo/cookbooks/golang/metadata.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/golang/metadata.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/golang/metadata.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,10 @@
+maintainer        "Matthew Baird"
+maintainer_email  "mattbaird@gmail.com"
+license           "Apache 2.0"
+description       "Installs go language from duh's Ubuntu PPA"
+long_description  IO.read(File.join(File.dirname(__FILE__), 'README.md'))
+version           "1.0.0"
+recipe            "golang", "Installs go"
+
+depends "apt"
+supports "ubuntu"
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/golang/recipes/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/golang/recipes/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/golang/recipes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/golang/recipes/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,35 @@
+#
+# Cookbook Name:: golang
+# Recipe:: default
+#
+# Copyright 2012, Michael S. Klishin, Travis CI Development Team
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+include_recipe "golang::ppa"
+#    echo 'export GOBIN=#{node['golang']['gobin']}' >> /home/vagrant/.bash_golang
+#    echo 'export GOROOT=/usr/local/go/' >> /home/vagrant/.bash_golang
+
+bash "Export ENV Vars" do
+  code <<-EOC
+    mkdir -p /home/vagrant/code/go/
+    chown vagrant /home/vagrant/code/go/
+    echo 'export GOPATH=/home/vagrant/code/go/' >> /home/vagrant/.bash_golang
+    echo 'export GOROOT=/usr/lib/go/' >> /home/vagrant/.bash_golang
+    echo 'export PATH=$PATH:$GOBIN' >> /home/vagrant/.bash_golang
+    echo 'source /home/vagrant/.bash_golang' >> /home/vagrant/.bashrc
+    source /home/vagrant/.bashrc
+  EOC
+  creates "/home/vagrant/.bash_golang"
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/golang/recipes/ppa.rb b/src/github.com/mattbaird/elastigo/cookbooks/golang/recipes/ppa.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/golang/recipes/ppa.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/golang/recipes/ppa.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,33 @@
+#
+# Cookbook Name:: golang
+# Recipe:: ppa
+#
+# Copyright 2012, Michael S. Klishin, Travis CI Development Team
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+apt_repository "duh-ppa" do
+  uri          "http://ppa.launchpad.net/duh/golang/ubuntu"
+  distribution node['lsb']['codename']
+  components   ["main"]
+  key          "60480472"
+  keyserver    "keyserver.ubuntu.com"
+  action :add
+  notifies :run, "execute[apt-get update]", :immediately
+end
+
+package "golang" do
+#  version "1.1.1"
+  action :install
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/CHANGELOG.md b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/CHANGELOG.md
--- a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/CHANGELOG.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/CHANGELOG.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+## v1.0.0:
+
+* [COOK-1373] - README example correction
+* [COOK-1179] - LWRP for repo management
+
+For further discussion about possible changes to the LWRP, see
+COOK-879, whereby it may become a fully fledged provider for chef's
+built in scm_repo resource.
+
+## v0.7.1:
+
+* Current public release
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/CONTRIBUTING b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/CONTRIBUTING
--- a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/CONTRIBUTING	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/CONTRIBUTING	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,29 @@
+If you would like to contribute, please open a ticket in JIRA:
+
+* http://tickets.opscode.com
+
+Create the ticket in the COOK project and use the cookbook name as the
+component.
+
+For all code contributions, we ask that contributors sign a
+contributor license agreement (CLA). Instructions may be found here:
+
+* http://wiki.opscode.com/display/chef/How+to+Contribute
+
+When contributing changes to individual cookbooks, please do not
+modify the version number in the metadata.rb. Also please do not
+update the CHANGELOG.md for a new version. Not all changes to a
+cookbook may be merged and released in the same versions. Opscode will
+handle the version updates during the release process. You are welcome
+to correct typos or otherwise make updates to documentation in the
+README.
+
+If a contribution adds new platforms or platform versions, indicate
+such in the body of the commit message(s), and update the relevant
+COOK ticket. When writing commit messages, it is helpful for others if
+you indicate the COOK ticket. For example:
+
+    git commit -m '[COOK-1041] Updated pool resource to correctly delete.'
+
+In the ticket itself, it is also helpful if you include log output of
+a successful Chef run, but this is not absolutely required.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/LICENSE b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/LICENSE
--- a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/LICENSE	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,201 @@
+                              Apache License
+                        Version 2.0, January 2004
+                     http://www.apache.org/licenses/
+
+TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+1. Definitions.
+
+   "License" shall mean the terms and conditions for use, reproduction,
+   and distribution as defined by Sections 1 through 9 of this document.
+
+   "Licensor" shall mean the copyright owner or entity authorized by
+   the copyright owner that is granting the License.
+
+   "Legal Entity" shall mean the union of the acting entity and all
+   other entities that control, are controlled by, or are under common
+   control with that entity. For the purposes of this definition,
+   "control" means (i) the power, direct or indirect, to cause the
+   direction or management of such entity, whether by contract or
+   otherwise, or (ii) ownership of fifty percent (50%) or more of the
+   outstanding shares, or (iii) beneficial ownership of such entity.
+
+   "You" (or "Your") shall mean an individual or Legal Entity
+   exercising permissions granted by this License.
+
+   "Source" form shall mean the preferred form for making modifications,
+   including but not limited to software source code, documentation
+   source, and configuration files.
+
+   "Object" form shall mean any form resulting from mechanical
+   transformation or translation of a Source form, including but
+   not limited to compiled object code, generated documentation,
+   and conversions to other media types.
+
+   "Work" shall mean the work of authorship, whether in Source or
+   Object form, made available under the License, as indicated by a
+   copyright notice that is included in or attached to the work
+   (an example is provided in the Appendix below).
+
+   "Derivative Works" shall mean any work, whether in Source or Object
+   form, that is based on (or derived from) the Work and for which the
+   editorial revisions, annotations, elaborations, or other modifications
+   represent, as a whole, an original work of authorship. For the purposes
+   of this License, Derivative Works shall not include works that remain
+   separable from, or merely link (or bind by name) to the interfaces of,
+   the Work and Derivative Works thereof.
+
+   "Contribution" shall mean any work of authorship, including
+   the original version of the Work and any modifications or additions
+   to that Work or Derivative Works thereof, that is intentionally
+   submitted to Licensor for inclusion in the Work by the copyright owner
+   or by an individual or Legal Entity authorized to submit on behalf of
+   the copyright owner. For the purposes of this definition, "submitted"
+   means any form of electronic, verbal, or written communication sent
+   to the Licensor or its representatives, including but not limited to
+   communication on electronic mailing lists, source code control systems,
+   and issue tracking systems that are managed by, or on behalf of, the
+   Licensor for the purpose of discussing and improving the Work, but
+   excluding communication that is conspicuously marked or otherwise
+   designated in writing by the copyright owner as "Not a Contribution."
+
+   "Contributor" shall mean Licensor and any individual or Legal Entity
+   on behalf of whom a Contribution has been received by Licensor and
+   subsequently incorporated within the Work.
+
+2. Grant of Copyright License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   copyright license to reproduce, prepare Derivative Works of,
+   publicly display, publicly perform, sublicense, and distribute the
+   Work and such Derivative Works in Source or Object form.
+
+3. Grant of Patent License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   (except as stated in this section) patent license to make, have made,
+   use, offer to sell, sell, import, and otherwise transfer the Work,
+   where such license applies only to those patent claims licensable
+   by such Contributor that are necessarily infringed by their
+   Contribution(s) alone or by combination of their Contribution(s)
+   with the Work to which such Contribution(s) was submitted. If You
+   institute patent litigation against any entity (including a
+   cross-claim or counterclaim in a lawsuit) alleging that the Work
+   or a Contribution incorporated within the Work constitutes direct
+   or contributory patent infringement, then any patent licenses
+   granted to You under this License for that Work shall terminate
+   as of the date such litigation is filed.
+
+4. Redistribution. You may reproduce and distribute copies of the
+   Work or Derivative Works thereof in any medium, with or without
+   modifications, and in Source or Object form, provided that You
+   meet the following conditions:
+
+   (a) You must give any other recipients of the Work or
+       Derivative Works a copy of this License; and
+
+   (b) You must cause any modified files to carry prominent notices
+       stating that You changed the files; and
+
+   (c) You must retain, in the Source form of any Derivative Works
+       that You distribute, all copyright, patent, trademark, and
+       attribution notices from the Source form of the Work,
+       excluding those notices that do not pertain to any part of
+       the Derivative Works; and
+
+   (d) If the Work includes a "NOTICE" text file as part of its
+       distribution, then any Derivative Works that You distribute must
+       include a readable copy of the attribution notices contained
+       within such NOTICE file, excluding those notices that do not
+       pertain to any part of the Derivative Works, in at least one
+       of the following places: within a NOTICE text file distributed
+       as part of the Derivative Works; within the Source form or
+       documentation, if provided along with the Derivative Works; or,
+       within a display generated by the Derivative Works, if and
+       wherever such third-party notices normally appear. The contents
+       of the NOTICE file are for informational purposes only and
+       do not modify the License. You may add Your own attribution
+       notices within Derivative Works that You distribute, alongside
+       or as an addendum to the NOTICE text from the Work, provided
+       that such additional attribution notices cannot be construed
+       as modifying the License.
+
+   You may add Your own copyright statement to Your modifications and
+   may provide additional or different license terms and conditions
+   for use, reproduction, or distribution of Your modifications, or
+   for any such Derivative Works as a whole, provided Your use,
+   reproduction, and distribution of the Work otherwise complies with
+   the conditions stated in this License.
+
+5. Submission of Contributions. Unless You explicitly state otherwise,
+   any Contribution intentionally submitted for inclusion in the Work
+   by You to the Licensor shall be under the terms and conditions of
+   this License, without any additional terms or conditions.
+   Notwithstanding the above, nothing herein shall supersede or modify
+   the terms of any separate license agreement you may have executed
+   with Licensor regarding such Contributions.
+
+6. Trademarks. This License does not grant permission to use the trade
+   names, trademarks, service marks, or product names of the Licensor,
+   except as required for reasonable and customary use in describing the
+   origin of the Work and reproducing the content of the NOTICE file.
+
+7. Disclaimer of Warranty. Unless required by applicable law or
+   agreed to in writing, Licensor provides the Work (and each
+   Contributor provides its Contributions) on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+   implied, including, without limitation, any warranties or conditions
+   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+   PARTICULAR PURPOSE. You are solely responsible for determining the
+   appropriateness of using or redistributing the Work and assume any
+   risks associated with Your exercise of permissions under this License.
+
+8. Limitation of Liability. In no event and under no legal theory,
+   whether in tort (including negligence), contract, or otherwise,
+   unless required by applicable law (such as deliberate and grossly
+   negligent acts) or agreed to in writing, shall any Contributor be
+   liable to You for damages, including any direct, indirect, special,
+   incidental, or consequential damages of any character arising as a
+   result of this License or out of the use or inability to use the
+   Work (including but not limited to damages for loss of goodwill,
+   work stoppage, computer failure or malfunction, or any and all
+   other commercial damages or losses), even if such Contributor
+   has been advised of the possibility of such damages.
+
+9. Accepting Warranty or Additional Liability. While redistributing
+   the Work or Derivative Works thereof, You may choose to offer,
+   and charge a fee for, acceptance of support, warranty, indemnity,
+   or other liability obligations and/or rights consistent with this
+   License. However, in accepting such obligations, You may act only
+   on Your own behalf and on Your sole responsibility, not on behalf
+   of any other Contributor, and only if You agree to indemnify,
+   defend, and hold each Contributor harmless for any liability
+   incurred by, or claims asserted against, such Contributor by reason
+   of your accepting any such warranty or additional liability.
+
+END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+   To apply the Apache License to your work, attach the following
+   boilerplate notice, with the fields enclosed by brackets "[]"
+   replaced with your own identifying information. (Don't include
+   the brackets!)  The text should be enclosed in the appropriate
+   comment syntax for the file format. We also recommend that a
+   file or class name and description of purpose be included on the
+   same "printed page" as the copyright notice for easier
+   identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/README.md b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/README.md
--- a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/README.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,69 @@
+Description
+===========
+
+Installs mercurial
+
+Requirements
+============
+
+A package named "mercurial" must exist in the platform package
+management system.
+
+Usage
+=====
+
+Install mercurial to make sure it is available to check out code from
+mercurial repositories.
+
+Resource/Provider
+=================
+
+This cookbook includes LWRPs for managing: mercurial
+
+mercurial
+---------
+
+### Actions
+
+- :clone - this will simply issue a clone of the repository at the revision specified (default tip).
+- :sync -  this will issue a clone of the repository if there is nothing at the path specified, otherwise a pull and update will be issued to bring the directory up-to-date.
+
+### Parameter Attributes
+
+- `path` - **Name attribute** path where the repository is checked
+  out.
+- `repository` - Repository to check out
+- `reference` - Reference in the repository
+- `key` - a private key on disk to use, for private repositories, must
+  already exist.
+- `owner` - local user that the clone is run as
+- `group` - local group that the clone is run as
+- `mode` - permissions of the cloned repository
+
+### Example
+
+	mercurial "/home/site/checkouts/www" do
+      repository "ssh://hg@bitbucket.org/niallsco/chef-hg"
+      reference "tip"
+      key "/home/site/.ssh/keyname"
+      action :sync
+    end
+
+License and Author
+==================
+
+Author:: Joshua Timberman <joshua@opscode.com>
+
+Copyright:: 2009, Opscode, Inc
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/metadata.rb b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/metadata.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/metadata.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/metadata.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,11 @@
+maintainer        "Opscode, Inc."
+maintainer_email  "cookbooks@opscode.com"
+license           "Apache 2.0"
+description       "Installs mercurial"
+version           "0.8.0"
+
+recipe "mercurial", "Installs mercurial"
+
+%w{ debian ubuntu }.each do |os|
+  supports os
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/providers/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/providers/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/providers/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/providers/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,34 @@
+action :sync do
+  execute "sync repository #{new_resource.path}" do    
+    not_if "hg identify #{new_resource.path}"
+    command "hg clone -e 'ssh -i #{new_resource.key} -o StrictHostKeyChecking=no' #{new_resource.repository} #{new_resource.path}"
+  end
+  execute "pull changes #{new_resource.path}" do
+      command "cd #{new_resource.path} && hg pull -e 'ssh -i #{new_resource.key} -o StrictHostKeyChecking=no' #{new_resource.repository}"
+  end
+  execute "update #{new_resource.path}" do
+      command "cd #{new_resource.path} && hg update -r #{new_resource.reference}"
+  end
+  execute "sync update owner #{new_resource.path}" do
+    command "chown -R #{new_resource.owner}:#{new_resource.group} #{new_resource.path}"
+  end
+  execute "sync update permissions #{new_resource.path}" do
+    command "chmod -R #{new_resource.mode} #{new_resource.path}"
+  end
+end
+ 
+action :clone do
+  execute "clone repository #{new_resource.path}" do
+    not_if "hg identify #{new_resource.path}"
+    command "hg clone -e 'ssh -i #{new_resource.key} -o StrictHostKeyChecking=no' #{new_resource.repository} #{new_resource.path}"
+  end
+  if new_resource.reference
+      command "cd #{new_resource.path} && hg update -r #{new_resource.reference}"
+  end
+  execute "update owner #{new_resource.path}" do
+    command "chown -R #{new_resource.owner}:#{new_resource.group} #{new_resource.path}"
+  end
+  execute "update permissions #{new_resource.path}" do
+    command "chmod -R #{new_resource.mode} #{new_resource.path}"
+  end
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/recipes/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/recipes/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/recipes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/recipes/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,21 @@
+#
+# Cookbook Name:: mercurial
+# Recipe:: default
+#
+# Copyright 2009, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+package "mercurial" do
+  action :upgrade
+end
diff -ruN a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/resources/default.rb b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/resources/default.rb
--- a/src/github.com/mattbaird/elastigo/cookbooks/mercurial/resources/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/cookbooks/mercurial/resources/default.rb	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,9 @@
+actions :sync, :clone
+
+attribute :path, :kind_of => String, :name_attribute => true
+attribute :repository, :kind_of => String
+attribute :reference, :kind_of => [Integer, String]
+attribute :key, :kind_of => String
+attribute :owner, :kind_of => String
+attribute :group, :kind_of => String
+attribute :mode, :kind_of => String, :default => '0775'
diff -ruN a/src/github.com/mattbaird/elastigo/core/bulk.go b/src/github.com/mattbaird/elastigo/core/bulk.go
--- a/src/github.com/mattbaird/elastigo/core/bulk.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/bulk.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,462 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"bytes"
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"io"
+	"log"
+	"strconv"
+	"sync"
+	"time"
+)
+
+var (
+	// Max buffer size in bytes before flushing to elasticsearch
+	BulkMaxBuffer = 1048576
+	// Max number of Docs to hold in buffer before forcing flush
+	BulkMaxDocs = 100
+	// Max delay before forcing a flush to Elasticearch
+	BulkDelaySeconds = 5
+	// Keep a running total of errors seen, since it is in the background
+	BulkErrorCt uint64
+	// maximum wait shutdown seconds
+	MAX_SHUTDOWN_SECS = 5
+
+	// There is one Global Bulk Indexer for convenience
+	GlobalBulkIndexer *BulkIndexer
+)
+
+type ErrorBuffer struct {
+	Err error
+	Buf *bytes.Buffer
+}
+
+// There is one global bulk indexer available for convenience so the IndexBulk() function can be called.
+// However, the recommended usage is create your own BulkIndexer to allow for multiple seperate elasticsearch
+// servers/host connections.
+//    @maxConns is the max number of in flight http requests
+//    @done is a channel to cause the indexer to stop
+//
+//   done := make(chan bool)
+//   BulkIndexerGlobalRun(100, done)
+func BulkIndexerGlobalRun(maxConns int, done chan bool) {
+	if GlobalBulkIndexer == nil {
+		GlobalBulkIndexer = NewBulkIndexer(maxConns)
+		GlobalBulkIndexer.Run(done)
+	}
+}
+
+// A bulk indexer creates goroutines, and channels for connecting and sending data
+// to elasticsearch in bulk, using buffers.
+type BulkIndexer struct {
+
+	// We are creating a variable defining the func responsible for sending
+	// to allow a mock sendor for test purposes
+	BulkSendor func(*bytes.Buffer) error
+
+	// If we encounter an error in sending, we are going to retry for this long
+	// before returning an error
+	// if 0 it will not retry
+	RetryForSeconds int
+
+	// channel for getting errors
+	ErrorChannel chan *ErrorBuffer
+
+	// channel for sending to background indexer
+	bulkChannel chan []byte
+
+	// shutdown channel
+	shutdownChan chan bool
+	// Channel to shutdown http send go-routines
+	httpDoneChan chan bool
+	// channel to shutdown timer
+	timerDoneChan chan bool
+	// channel to shutdown doc go-routines
+	docDoneChan chan bool
+
+	// Channel to send a complete byte.Buffer to the http sendor
+	sendBuf chan *bytes.Buffer
+	// byte buffer for docs that have been converted to bytes, but not yet sent
+	buf *bytes.Buffer
+	// Buffer for Max number of time before forcing flush
+	BufferDelayMax time.Duration
+	// Max buffer size in bytes before flushing to elasticsearch
+	BulkMaxBuffer int // 1048576
+	// Max number of Docs to hold in buffer before forcing flush
+	BulkMaxDocs int // 100
+
+	// Number of documents we have send through so far on this session
+	docCt int
+	// Max number of http connections in flight at one time
+	maxConns int
+	// If we are indexing enough docs per bufferdelaymax, we won't need to do time
+	// based eviction, else we do.
+	needsTimeBasedFlush bool
+	// Lock for document writes/operations
+	mu sync.Mutex
+	// Wait Group for the http sends
+	sendWg *sync.WaitGroup
+}
+
+func NewBulkIndexer(maxConns int) *BulkIndexer {
+	b := BulkIndexer{sendBuf: make(chan *bytes.Buffer, maxConns)}
+	b.needsTimeBasedFlush = true
+	b.buf = new(bytes.Buffer)
+	b.maxConns = maxConns
+	b.BulkMaxBuffer = BulkMaxBuffer
+	b.BulkMaxDocs = BulkMaxDocs
+	b.BufferDelayMax = time.Duration(BulkDelaySeconds) * time.Second
+	b.bulkChannel = make(chan []byte, 100)
+	b.sendWg = new(sync.WaitGroup)
+	b.docDoneChan = make(chan bool)
+	b.timerDoneChan = make(chan bool)
+	b.httpDoneChan = make(chan bool)
+	return &b
+}
+
+// A bulk indexer with more control over error handling
+//    @maxConns is the max number of in flight http requests
+//    @retrySeconds is # of seconds to wait before retrying falied requests
+//
+//   done := make(chan bool)
+//   BulkIndexerGlobalRun(100, done)
+func NewBulkIndexerErrors(maxConns, retrySeconds int) *BulkIndexer {
+	b := NewBulkIndexer(maxConns)
+	b.RetryForSeconds = retrySeconds
+	b.ErrorChannel = make(chan *ErrorBuffer, 20)
+	return b
+}
+
+// Starts this bulk Indexer running, this Run opens a go routine so is
+// Non blocking
+func (b *BulkIndexer) Run(done chan bool) {
+
+	go func() {
+		if b.BulkSendor == nil {
+			b.BulkSendor = BulkSend
+		}
+		b.shutdownChan = done
+		b.startHttpSendor()
+		b.startDocChannel()
+		b.startTimer()
+		<-b.shutdownChan
+		b.Flush()
+		b.shutdown()
+	}()
+}
+
+// Make a channel that will close when the given WaitGroup is done.
+func wgChan(wg *sync.WaitGroup) <-chan interface{} {
+	ch := make(chan interface{})
+	go func() {
+		wg.Wait()
+		close(ch)
+	}()
+	return ch
+}
+
+// Flush all current documents to ElasticSearch
+func (b *BulkIndexer) Flush() {
+	b.mu.Lock()
+	if b.docCt > 0 {
+		b.send(b.buf)
+	}
+	b.mu.Unlock()
+	for {
+		select {
+		case <-wgChan(b.sendWg):
+			// done
+			log.Println("BulkIndexor Wait Group Shutdown")
+			return
+		case <-time.After(time.Second * time.Duration(MAX_SHUTDOWN_SECS)):
+			// timeout!
+			log.Println("BulkIndexor Timeout in Shutdown!")
+			return
+		}
+	}
+}
+
+func (b *BulkIndexer) startHttpSendor() {
+
+	// this sends http requests to elasticsearch it uses maxConns to open up that
+	// many goroutines, each of which will synchronously call ElasticSearch
+	// in theory, the whole set will cause a backup all the way to IndexBulk if
+	// we have consumed all maxConns
+	for i := 0; i < b.maxConns; i++ {
+		go func() {
+			for {
+				select {
+				case buf := <-b.sendBuf:
+					b.sendWg.Add(1)
+					err := b.BulkSendor(buf)
+
+					// Perhaps a b.FailureStrategy(err)  ??  with different types of strategies
+					//  1.  Retry, then panic
+					//  2.  Retry then return error and let runner decide
+					//  3.  Retry, then log to disk?   retry later?
+					if err != nil {
+						if b.RetryForSeconds > 0 {
+							time.Sleep(time.Second * time.Duration(b.RetryForSeconds))
+							err = b.BulkSendor(buf)
+							if err == nil {
+								// Successfully re-sent with no error
+								b.sendWg.Done()
+								continue
+							}
+						}
+						if b.ErrorChannel != nil {
+							log.Println(err)
+							b.ErrorChannel <- &ErrorBuffer{err, buf}
+						}
+					}
+					b.sendWg.Done()
+				case <-b.httpDoneChan:
+					// shutdown this go routine
+					return
+				}
+
+			}
+		}()
+	}
+}
+
+// start a timer for checking back and forcing flush ever BulkDelaySeconds seconds
+// even if we haven't hit max messages/size
+func (b *BulkIndexer) startTimer() {
+	ticker := time.NewTicker(b.BufferDelayMax)
+	log.Println("Starting timer with delay = ", b.BufferDelayMax)
+	go func() {
+		for {
+			select {
+			case <-ticker.C:
+				b.mu.Lock()
+				// don't send unless last sendor was the time,
+				// otherwise an indication of other thresholds being hit
+				// where time isn't needed
+				if b.buf.Len() > 0 && b.needsTimeBasedFlush {
+					b.needsTimeBasedFlush = true
+					b.send(b.buf)
+				} else if b.buf.Len() > 0 {
+					b.needsTimeBasedFlush = true
+				}
+				b.mu.Unlock()
+			case <-b.timerDoneChan:
+				// shutdown this go routine
+				return
+			}
+
+		}
+	}()
+}
+
+func (b *BulkIndexer) startDocChannel() {
+	// This goroutine accepts incoming byte arrays from the IndexBulk function and
+	// writes to buffer
+	go func() {
+		for {
+			select {
+			case docBytes := <-b.bulkChannel:
+				b.mu.Lock()
+				b.docCt += 1
+				b.buf.Write(docBytes)
+				if b.buf.Len() >= b.BulkMaxBuffer || b.docCt >= b.BulkMaxDocs {
+					b.needsTimeBasedFlush = false
+					//log.Printf("Send due to size:  docs=%d  bufsize=%d", b.docCt, b.buf.Len())
+					b.send(b.buf)
+				}
+				b.mu.Unlock()
+			case <-b.docDoneChan:
+				// shutdown this go routine
+				return
+			}
+		}
+	}()
+}
+
+func (b *BulkIndexer) send(buf *bytes.Buffer) {
+	//b2 := *b.buf
+	b.sendBuf <- buf
+	b.buf = new(bytes.Buffer)
+	b.docCt = 0
+}
+
+func (b *BulkIndexer) shutdown() {
+	// This must be called After flush
+	b.docDoneChan <- true
+	log.Println("Just sent to doc chan done")
+	b.timerDoneChan <- true
+	for i := 0; i < b.maxConns; i++ {
+		b.httpDoneChan <- true
+	}
+}
+
+// The index bulk API adds or updates a typed JSON document to a specific index, making it searchable.
+// it operates by buffering requests, and ocassionally flushing to elasticsearch
+// http://www.elasticsearch.org/guide/reference/api/bulk.html
+func (b *BulkIndexer) Index(index string, _type string, id, ttl string, date *time.Time, data interface{}) error {
+	//{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	by, err := WriteBulkBytes("index", index, _type, id, ttl, date, data)
+	if err != nil {
+		log.Println(err)
+		return err
+	}
+	b.bulkChannel <- by
+	return nil
+}
+
+func (b *BulkIndexer) Update(index string, _type string, id, ttl string, date *time.Time, data interface{}) error {
+	//{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	by, err := WriteBulkBytes("update", index, _type, id, ttl, date, data)
+	if err != nil {
+		log.Println(err)
+		return err
+	}
+	b.bulkChannel <- by
+	return nil
+}
+
+// This does the actual send of a buffer, which has already been formatted
+// into bytes of ES formatted bulk data
+func BulkSend(buf *bytes.Buffer) error {
+	_, err := api.DoCommand("POST", "/_bulk", buf)
+	if err != nil {
+		log.Println(err)
+		BulkErrorCt += 1
+		return err
+	}
+	return nil
+}
+
+// Given a set of arguments for index, type, id, data create a set of bytes that is formatted for bulkd index
+// http://www.elasticsearch.org/guide/reference/api/bulk.html
+func WriteBulkBytes(op string, index string, _type string, id, ttl string, date *time.Time, data interface{}) ([]byte, error) {
+	// only index and update are currently supported
+	if op != "index" && op != "update" {
+		return nil, errors.New(fmt.Sprintf("Operation '%s' is not yet supported", op))
+	}
+
+	// First line
+	buf := bytes.Buffer{}
+	buf.WriteString(fmt.Sprintf(`{"%s":{"_index":"`, op))
+	buf.WriteString(index)
+	buf.WriteString(`","_type":"`)
+	buf.WriteString(_type)
+	if len(id) > 0 {
+		buf.WriteString(`","_id":"`)
+		buf.WriteString(id)
+	}
+
+	if op == "update" {
+		buf.WriteString(`","retry_on_conflict":"3`)
+		buf.WriteString(ttl)
+	}
+
+	if len(ttl) > 0 {
+		buf.WriteString(`","ttl":"`)
+		buf.WriteString(ttl)
+	}
+	if date != nil {
+		buf.WriteString(`","_timestamp":"`)
+		buf.WriteString(strconv.FormatInt(date.UnixNano()/1e6, 10))
+	}
+	buf.WriteString(`"}}`)
+	buf.WriteByte('\n')
+
+	switch v := data.(type) {
+	case *bytes.Buffer:
+		io.Copy(&buf, v)
+	case []byte:
+		buf.Write(v)
+	case string:
+		buf.WriteString(v)
+	default:
+		body, jsonErr := json.Marshal(data)
+		if jsonErr != nil {
+			log.Println("Json data error ", data)
+			return nil, jsonErr
+		}
+		buf.Write(body)
+	}
+	buf.WriteByte('\n')
+	return buf.Bytes(), nil
+}
+
+// The index bulk API adds or updates a typed JSON document to a specific index, making it searchable.
+// it operates by buffering requests, and ocassionally flushing to elasticsearch
+//
+// This uses the one Global Bulk Indexer, you can also create your own non-global indexers and use the
+// Index functions of that
+//
+// http://www.elasticsearch.org/guide/reference/api/bulk.html
+func IndexBulk(index string, _type string, id string, date *time.Time, data interface{}) error {
+	//{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	if GlobalBulkIndexer == nil {
+		panic("Must have Global Bulk Indexer to use this Func")
+	}
+	by, err := WriteBulkBytes("index", index, _type, id, "", date, data)
+	if err != nil {
+		return err
+	}
+	GlobalBulkIndexer.bulkChannel <- by
+	return nil
+}
+
+func UpdateBulk(index string, _type string, id string, date *time.Time, data interface{}) error {
+	//{ "update" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	if GlobalBulkIndexer == nil {
+		panic("Must have Global Bulk Indexer to use this Func")
+	}
+	by, err := WriteBulkBytes("update", index, _type, id, "", date, data)
+	if err != nil {
+		return err
+	}
+	GlobalBulkIndexer.bulkChannel <- by
+	return nil
+}
+
+// The index bulk API adds or updates a typed JSON document to a specific index, making it searchable.
+// it operates by buffering requests, and ocassionally flushing to elasticsearch.
+//
+// This uses the one Global Bulk Indexer, you can also create your own non-global indexers and use the
+// IndexTtl functions of that
+//
+// http://www.elasticsearch.org/guide/reference/api/bulk.html
+func IndexBulkTtl(index string, _type string, id, ttl string, date *time.Time, data interface{}) error {
+	//{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	if GlobalBulkIndexer == nil {
+		panic("Must have Global Bulk Indexer to use this Func")
+	}
+	by, err := WriteBulkBytes("index", index, _type, id, ttl, date, data)
+	if err != nil {
+		return err
+	}
+	GlobalBulkIndexer.bulkChannel <- by
+	return nil
+}
+
+func UpdateBulkTtl(index string, _type string, id, ttl string, date *time.Time, data interface{}) error {
+	//{ "update" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	if GlobalBulkIndexer == nil {
+		panic("Must have Global Bulk Indexer to use this Func")
+	}
+	by, err := WriteBulkBytes("update", index, _type, id, ttl, date, data)
+	if err != nil {
+		return err
+	}
+	GlobalBulkIndexer.bulkChannel <- by
+	return nil
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/bulkUDP.go b/src/github.com/mattbaird/elastigo/core/bulkUDP.go
--- a/src/github.com/mattbaird/elastigo/core/bulkUDP.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/bulkUDP.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
diff -ruN a/src/github.com/mattbaird/elastigo/core/bulk_test.go b/src/github.com/mattbaird/elastigo/core/bulk_test.go
--- a/src/github.com/mattbaird/elastigo/core/bulk_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/bulk_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,246 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"bytes"
+	"crypto/rand"
+	"encoding/json"
+	"flag"
+	u "github.com/araddon/gou"
+	"github.com/mattbaird/elastigo/api"
+	"log"
+	"strconv"
+	"testing"
+	"time"
+)
+
+//  go test -bench=".*"
+//  go test -bench="Bulk"
+
+var (
+	buffers        = make([]*bytes.Buffer, 0)
+	totalBytesSent int
+	messageSets    int
+)
+
+func init() {
+	flag.Parse()
+	if testing.Verbose() {
+		u.SetupLogging("debug")
+	}
+}
+func TestBulkIndexerBasic(t *testing.T) {
+	InitTests(true)
+	indexer := NewBulkIndexer(3)
+	indexer.BulkSendor = func(buf *bytes.Buffer) error {
+		messageSets += 1
+		totalBytesSent += buf.Len()
+		buffers = append(buffers, buf)
+		u.Debug(string(buf.Bytes()))
+		return BulkSend(buf)
+	}
+	done := make(chan bool)
+	indexer.Run(done)
+
+	date := time.Unix(1257894000, 0)
+	data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0)}
+	err := indexer.Index("users", "user", "1", "", &date, data)
+
+	WaitFor(func() bool {
+		return len(buffers) > 0
+	}, 5)
+	// part of request is url, so lets factor that in
+	//totalBytesSent = totalBytesSent - len(*eshost)
+	u.Assert(len(buffers) == 1, t, "Should have sent one operation but was %d", len(buffers))
+	u.Assert(BulkErrorCt == 0 && err == nil, t, "Should not have any errors  %v", err)
+	u.Assert(totalBytesSent == 145, t, "Should have sent 135 bytes but was %v", totalBytesSent)
+
+	err = indexer.Index("users", "user", "2", "", nil, data)
+	<-time.After(time.Millisecond * 10) // we need to wait for doc to hit send channel
+	// this will test to ensure that Flush actually catches a doc
+	indexer.Flush()
+	totalBytesSent = totalBytesSent - len(*eshost)
+	u.Assert(err == nil, t, "Should have nil error  =%v", err)
+	u.Assert(len(buffers) == 2, t, "Should have another buffer ct=%d", len(buffers))
+
+	u.Assert(BulkErrorCt == 0, t, "Should not have any errors %d", BulkErrorCt)
+	u.Assert(u.CloseInt(totalBytesSent, 257), t, "Should have sent 257 bytes but was %v", totalBytesSent)
+
+	done <- true
+}
+
+func TestBulkUpdate(t *testing.T) {
+	InitTests(true)
+	api.Port = "9200"
+	indexer := NewBulkIndexer(3)
+	indexer.BulkSendor = func(buf *bytes.Buffer) error {
+		messageSets += 1
+		totalBytesSent += buf.Len()
+		buffers = append(buffers, buf)
+		u.Debug(string(buf.Bytes()))
+		return BulkSend(buf)
+	}
+	done := make(chan bool)
+	indexer.Run(done)
+
+	date := time.Unix(1257894000, 0)
+	user := map[string]interface{}{
+		"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0), "count": 1,
+	}
+
+	// Lets make sure the data is in the index ...
+	_, err := Index(true, "users", "user", "5", user)
+
+	// script and params
+	data := map[string]interface{}{
+		"script": "ctx._source.count += 2",
+	}
+	err = indexer.Update("users", "user", "5", "", &date, data)
+	// So here's the deal. Flushing does seem to work, you just have to give the
+	// channel a moment to recieve the message ...
+	//	<- time.After(time.Millisecond * 20)
+	//	indexer.Flush()
+	done <- true
+
+	WaitFor(func() bool {
+		return len(buffers) > 0
+	}, 5)
+
+	u.Assert(BulkErrorCt == 0 && err == nil, t, "Should not have any errors  %v", err)
+
+	response, err := Get(true, "users", "user", "5")
+	u.Assert(err == nil, t, "Should not have any errors  %v", err)
+	newCount := response.Source.(map[string]interface{})["count"]
+	u.Assert(newCount.(float64) == 3, t, "Should have update count: %#v ... %#v", response.Source.(map[string]interface{})["count"], response)
+}
+
+func TestBulkSmallBatch(t *testing.T) {
+	InitTests(true)
+
+	done := make(chan bool)
+
+	date := time.Unix(1257894000, 0)
+	data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0)}
+
+	// Now tests small batches
+	indexersm := NewBulkIndexer(1)
+	indexersm.BufferDelayMax = 100 * time.Millisecond
+	indexersm.BulkMaxDocs = 2
+	messageSets = 0
+	indexersm.BulkSendor = func(buf *bytes.Buffer) error {
+		messageSets += 1
+		return BulkSend(buf)
+	}
+	indexersm.Run(done)
+	<-time.After(time.Millisecond * 20)
+
+	indexersm.Index("users", "user", "2", "", &date, data)
+	indexersm.Index("users", "user", "3", "", &date, data)
+	indexersm.Index("users", "user", "4", "", &date, data)
+	<-time.After(time.Millisecond * 200)
+	//	indexersm.Flush()
+	done <- true
+	Assert(messageSets == 2, t, "Should have sent 2 message sets %d", messageSets)
+
+}
+
+func TestBulkErrors(t *testing.T) {
+	// lets set a bad port, and hope we get a connection refused error?
+	api.Port = "27845"
+	defer func() {
+		api.Port = "9200"
+	}()
+	BulkDelaySeconds = 1
+	indexer := NewBulkIndexerErrors(10, 1)
+	done := make(chan bool)
+	indexer.Run(done)
+
+	errorCt := 0
+	go func() {
+		for i := 0; i < 20; i++ {
+			date := time.Unix(1257894000, 0)
+			data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0)}
+			indexer.Index("users", "user", strconv.Itoa(i), "", &date, data)
+		}
+	}()
+	for errBuf := range indexer.ErrorChannel {
+		errorCt++
+		u.Debug(errBuf.Err)
+		break
+	}
+	u.Assert(errorCt > 0, t, "ErrorCt should be > 0 %d", errorCt)
+	done <- true
+}
+
+/*
+BenchmarkBulkSend	18:33:00 bulk_test.go:131: Sent 1 messages in 0 sets totaling 0 bytes
+18:33:00 bulk_test.go:131: Sent 100 messages in 1 sets totaling 145889 bytes
+18:33:01 bulk_test.go:131: Sent 10000 messages in 100 sets totaling 14608888 bytes
+18:33:05 bulk_test.go:131: Sent 20000 messages in 99 sets totaling 14462790 bytes
+   20000	    234526 ns/op
+
+*/
+func BenchmarkBulkSend(b *testing.B) {
+	InitTests(true)
+	b.StartTimer()
+	totalBytes := 0
+	sets := 0
+	GlobalBulkIndexer.BulkSendor = func(buf *bytes.Buffer) error {
+		totalBytes += buf.Len()
+		sets += 1
+		//log.Println("got bulk")
+		return BulkSend(buf)
+	}
+	for i := 0; i < b.N; i++ {
+		about := make([]byte, 1000)
+		rand.Read(about)
+		data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0), "about": about}
+		IndexBulk("users", "user", strconv.Itoa(i), nil, data)
+	}
+	log.Printf("Sent %d messages in %d sets totaling %d bytes \n", b.N, sets, totalBytes)
+	if BulkErrorCt != 0 {
+		b.Fail()
+	}
+}
+
+/*
+TODO:  this should be faster than above
+
+BenchmarkBulkSendBytes	18:33:05 bulk_test.go:169: Sent 1 messages in 0 sets totaling 0 bytes
+18:33:05 bulk_test.go:169: Sent 100 messages in 2 sets totaling 292299 bytes
+18:33:09 bulk_test.go:169: Sent 10000 messages in 99 sets totaling 14473800 bytes
+   10000	    373529 ns/op
+
+*/
+func BenchmarkBulkSendBytes(b *testing.B) {
+	InitTests(true)
+	about := make([]byte, 1000)
+	rand.Read(about)
+	data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0), "about": about}
+	body, _ := json.Marshal(data)
+	b.StartTimer()
+	totalBytes := 0
+	sets := 0
+	GlobalBulkIndexer.BulkSendor = func(buf *bytes.Buffer) error {
+		totalBytes += buf.Len()
+		sets += 1
+		return BulkSend(buf)
+	}
+	for i := 0; i < b.N; i++ {
+		IndexBulk("users", "user", strconv.Itoa(i), nil, body)
+	}
+	log.Printf("Sent %d messages in %d sets totaling %d bytes \n", b.N, sets, totalBytes)
+	if BulkErrorCt != 0 {
+		b.Fail()
+	}
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/count.go b/src/github.com/mattbaird/elastigo/core/count.go
--- a/src/github.com/mattbaird/elastigo/core/count.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/count.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,49 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+type CountResponse struct {
+	Count int        `json:"count"`
+	Shard api.Status `json:"_shards"`
+}
+
+// Count allows the caller to easily execute a query and get the number of matches for that query.
+// It can be executed across one or more indices and across one or more types.
+// The query can either be provided using a simple query string as a parameter,
+// or using the Query DSL defined within the request body.
+// http://www.elasticsearch.org/guide/reference/api/count.html
+// TODO: take parameters.
+// currently not working against 0.19.10
+func Count(pretty bool, index string, _type string) (CountResponse, error) {
+	var url string
+	var retval CountResponse
+	url = fmt.Sprintf("/%s/%s/_count?%s", index, _type, api.Pretty(pretty))
+	body, err := api.DoCommand("GET", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	//fmt.Println(body)
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/delete.go b/src/github.com/mattbaird/elastigo/core/delete.go
--- a/src/github.com/mattbaird/elastigo/core/delete.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/delete.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,40 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// Delete API allows to delete a typed JSON document from a specific index based on its id.
+// http://www.elasticsearch.org/guide/reference/api/delete.html
+// todo: add routing and versioning support
+func Delete(pretty bool, index string, _type string, id string, version int, routing string) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url = fmt.Sprintf("/%s/%s/%s?%s", index, _type, id, api.Pretty(pretty))
+	body, err := api.DoCommand("DELETE", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	//fmt.Println(body)
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/deleteByQuery.go b/src/github.com/mattbaird/elastigo/core/deleteByQuery.go
--- a/src/github.com/mattbaird/elastigo/core/deleteByQuery.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/deleteByQuery.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,59 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"strings"
+)
+
+// DeleteByQuery allows the caller to delete documents from one or more indices and one or more types based on a query.
+// The query can either be provided using a simple query string as a parameter, or using the Query DSL defined within
+// the request body.
+// see: http://www.elasticsearch.org/guide/reference/api/delete-by-query.html
+func DeleteByQuery(pretty bool, indices []string, types []string, query interface{}) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(indices) > 0 && len(types) > 0 {
+		url = fmt.Sprintf("http://localhost:9200/%s/%s/_query?%s&%s", strings.Join(indices, ","), strings.Join(types, ","), buildQuery(), api.Pretty(pretty))
+	} else if len(indices) > 0 {
+		url = fmt.Sprintf("http://localhost:9200/%s/_query?%s&%s", strings.Join(indices, ","), buildQuery(), api.Pretty(pretty))
+	}
+	body, err := api.DoCommand("DELETE", url, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
+
+func buildQuery() string {
+	return ""
+}
+
+type DeleteByQueryResponse struct {
+	Status   bool                   `json:"ok"`
+	Indicies map[string]IndexStatus `json:"_indices"`
+}
+
+type IndexStatus struct {
+	Shards api.Status `json:"_shards"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/example_test.go b/src/github.com/mattbaird/elastigo/core/example_test.go
--- a/src/github.com/mattbaird/elastigo/core/example_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/example_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,106 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core_test
+
+import (
+	"bytes"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"github.com/mattbaird/elastigo/core"
+	"strconv"
+	"time"
+)
+
+// The simplest usage of background bulk indexing
+func ExampleBulkIndexer_simple() {
+	indexer := core.NewBulkIndexerErrors(10, 60)
+	done := make(chan bool)
+	indexer.Run(done)
+
+	indexer.Index("twitter", "user", "1", "", nil, `{"name":"bob"}`)
+
+	<-done // wait forever
+}
+
+// The simplest usage of background bulk indexing with error channel
+func ExampleBulkIndexer_errorchannel() {
+	indexer := core.NewBulkIndexerErrors(10, 60)
+	done := make(chan bool)
+	indexer.Run(done)
+
+	go func() {
+		for errBuf := range indexer.ErrorChannel {
+			// just blissfully print errors forever
+			fmt.Println(errBuf.Err)
+		}
+	}()
+	for i := 0; i < 20; i++ {
+		indexer.Index("twitter", "user", strconv.Itoa(i), "", nil, `{"name":"bob"}`)
+	}
+	done <- true
+}
+
+// The simplest usage of background bulk indexing with error channel
+func ExampleBulkIndexer_errorsmarter() {
+	indexer := core.NewBulkIndexerErrors(10, 60)
+	done := make(chan bool)
+	indexer.Run(done)
+
+	errorCt := 0 // use sync.atomic or something if you need
+	timer := time.NewTicker(time.Minute * 3)
+	go func() {
+		for {
+			select {
+			case _ = <-timer.C:
+				if errorCt < 2 {
+					errorCt = 0
+				}
+			case _ = <-done:
+				return
+			}
+		}
+	}()
+
+	go func() {
+		for errBuf := range indexer.ErrorChannel {
+			errorCt++
+			fmt.Println(errBuf.Err)
+			// log to disk?  db?   ????  Panic
+		}
+	}()
+	for i := 0; i < 20; i++ {
+		indexer.Index("twitter", "user", strconv.Itoa(i), "", nil, `{"name":"bob"}`)
+	}
+	done <- true // send shutdown signal
+}
+
+// The inspecting the response
+func ExampleBulkIndexer_responses() {
+	indexer := core.NewBulkIndexer(10)
+	// Create a custom Sendor Func, to allow inspection of response/error
+	indexer.BulkSendor = func(buf *bytes.Buffer) error {
+		// @buf is the buffer of docs about to be written
+		respJson, err := api.DoCommand("POST", "/_bulk", buf)
+		if err != nil {
+			// handle it better than this
+			fmt.Println(string(respJson))
+		}
+		return err
+	}
+	done := make(chan bool)
+	indexer.Run(done)
+
+	for i := 0; i < 20; i++ {
+		indexer.Index("twitter", "user", strconv.Itoa(i), "", nil, `{"name":"bob"}`)
+	}
+	done <- true // send shutdown signal
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/explain.go b/src/github.com/mattbaird/elastigo/core/explain.go
--- a/src/github.com/mattbaird/elastigo/core/explain.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/explain.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,45 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// Explain computes a score explanation for a query and a specific document.
+// This can give useful feedback whether a document matches or didnt match a specific query.
+// This feature is available from version 0.19.9 and up.
+// see http://www.elasticsearch.org/guide/reference/api/explain.html
+func Explain(pretty bool, index string, _type string, id string, query string) (api.Match, error) {
+	var url string
+	var retval api.Match
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/_explain?%s", index, _type, api.Pretty(pretty))
+	} else {
+		url = fmt.Sprintf("/%s/_explain?%s", index, api.Pretty(pretty))
+	}
+	body, err := api.DoCommand("GET", url, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/get.go b/src/github.com/mattbaird/elastigo/core/get.go
--- a/src/github.com/mattbaird/elastigo/core/get.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/get.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,88 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// Get allows caller to get a typed JSON document from the index based on its id.
+// GET - retrieves the doc
+// HEAD - checks for existence of the doc
+// http://www.elasticsearch.org/guide/reference/api/get.html
+// TODO: make this implement an interface
+func Get(pretty bool, index string, _type string, id string) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/%s?%s", index, _type, id, api.Pretty(pretty))
+	} else {
+		url = fmt.Sprintf("/%s/%s?%s", index, id, api.Pretty(pretty))
+	}
+	body, err := api.DoCommand("GET", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	//fmt.Println(body)
+	return retval, err
+}
+
+// GetSource retrieves the document by id and converts it to provided interface
+func GetSource(index string, _type string, id string, source interface{}) error {
+	url := fmt.Sprintf("/%s/%s/%s/_source", index, _type, id)
+	body, err := api.DoCommand("GET", url, nil)
+	if err == nil {
+		err = json.Unmarshal(body, &source)
+	}
+	//fmt.Println(body)
+	return err
+}
+
+// Exists allows caller to check for the existance of a document using HEAD
+func Exists(pretty bool, index string, _type string, id string) (bool, error) {
+
+	var url string
+
+	var response map[string]interface{}
+
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/%s?fields=_id%s", index, _type, id, api.Pretty(pretty))
+	} else {
+		url = fmt.Sprintf("/%s/%s?fields=_id%s", index, id, api.Pretty(pretty))
+	}
+
+	req, err := api.ElasticSearchRequest("HEAD", url)
+
+	if err != nil {
+		fmt.Println(err)
+	}
+
+	httpStatusCode, _, err := req.Do(&response)
+
+	if err != nil {
+		return false, err
+	}
+	if httpStatusCode == 404 {
+		return false, err
+	} else {
+		return true, err
+	}
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/index.go b/src/github.com/mattbaird/elastigo/core/index.go
--- a/src/github.com/mattbaird/elastigo/core/index.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/index.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,128 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"net/url"
+	"strconv"
+)
+
+// Index adds or updates a typed JSON document in a specific index, making it searchable, creating an index
+// if it did not exist.
+// if id is omited, op_type 'create' will be pased and http method will default to "POST"
+// id is optional
+// parentId is optional
+// version is optional
+// op_type is optional
+// routing is optional
+// timestamp is optional
+// ttl is optional
+// percolate is optional
+// timeout is optional
+// http://www.elasticsearch.org/guide/reference/api/index_.html
+func Index(pretty bool, index string, _type string, id string, data interface{}) (api.BaseResponse, error) {
+	return IndexWithParameters(pretty, index, _type, id, "", 0, "", "", "", 0, "", "", false, data)
+}
+
+// IndexWithParameters takes all the potential parameters available
+func IndexWithParameters(pretty bool, index string, _type string, id string, parentId string, version int, op_type string,
+	routing string, timestamp string, ttl int, percolate string, timeout string, refresh bool, data interface{}) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url, err := GetIndexUrl(index, _type, id, parentId, version, op_type, routing, timestamp, ttl, percolate, timeout, refresh)
+	if err != nil {
+		return retval, err
+	}
+	var method string
+	if len(id) == 0 {
+		method = "POST"
+	} else {
+		method = "PUT"
+	}
+
+	body, err := api.DoCommand(method, url, data)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func GetIndexUrl(index string, _type string, id string, parentId string, version int, op_type string,
+	routing string, timestamp string, ttl int, percolate string, timeout string, refresh bool) (retval string, e error) {
+
+	if len(index) == 0 {
+		return "", errors.New("index can not be blank")
+	}
+	if len(_type) == 0 {
+		return "", errors.New("_type can not be blank")
+	}
+	var partialURL string
+	var values url.Values = url.Values{}
+	partialURL = fmt.Sprintf("/%s/%s", index, _type)
+	if len(id) > 0 {
+		partialURL = fmt.Sprintf("%s/%s", partialURL, id)
+	}
+	// A child document can be indexed by specifying its parent when indexing.
+	if len(parentId) > 0 {
+		values.Add("parent", parentId)
+	}
+	// versions start at 1, so if greater than 0
+	if version > 0 {
+		values.Add("version", strconv.Itoa(version))
+	}
+	if len(op_type) > 0 {
+		if len(id) == 0 {
+			//if id is omited, op_type defaults to 'create'
+			values.Add("op_type", "create")
+		} else {
+			values.Add("op_type", op_type)
+		}
+	}
+	if len(routing) > 0 {
+		values.Add("routing", routing)
+	}
+	// A document can be indexed with a timestamp associated with it.
+	// The timestamp value of a document can be set using the timestamp parameter.
+	if len(timestamp) > 0 {
+		values.Add("timestamp", timestamp)
+	}
+	// A document can be indexed with a ttl (time to live) associated with it. Expired documents
+	// will be expunged automatically.
+	if ttl > 0 {
+		values.Add("ttl", strconv.Itoa(ttl))
+	}
+	if len(percolate) > 0 {
+		values.Add("percolate", percolate)
+	}
+	// example 5m
+	if len(timeout) > 0 {
+		values.Add("timeout", timeout)
+	}
+
+	if refresh {
+		values.Add("refresh", "true")
+	}
+
+	partialURL += "?" + values.Encode()
+	return partialURL, nil
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/index_test.go b/src/github.com/mattbaird/elastigo/core/index_test.go
--- a/src/github.com/mattbaird/elastigo/core/index_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/index_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,107 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"fmt"
+	u "github.com/araddon/gou"
+	"testing"
+)
+
+func TestUrlGeneration(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&parent=Parent&percolate=Percolate&refresh=true&routing=Routing&timeout=Timeout&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 1, "create", "Routing", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGeneration Should get %s, instead got %s", expectedUrl, url))
+}
+
+func TestUrlGenerationNoIndex(t *testing.T) {
+	_, err := GetIndexUrl("", "Type", "Id", "Parent", 1, "create", "Routing", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err != nil, t, "err should have been returned")
+}
+
+func TestUrlGenerationNoType(t *testing.T) {
+	_, err := GetIndexUrl("Index", "", "Id", "Parent", 1, "create", "Routing", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err != nil, t, "err should have been returned")
+}
+
+func TestUrlGenerationNoId(t *testing.T) {
+	expectedUrl := "/Index/Type?op_type=create&parent=Parent&percolate=Percolate&refresh=true&routing=Routing&timeout=Timeout&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "", "Parent", 1, "create", "Routing", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoId Should get %s, instead got %s", expectedUrl, url))
+}
+
+// if Id is blank, op_type should default to create
+func TestUrlGenerationNoIdAndOpTypeNotCreate(t *testing.T) {
+	expectedUrl := "/Index/Type?op_type=create&parent=Parent&percolate=Percolate&refresh=true&routing=Routing&timeout=Timeout&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "", "Parent", 1, "notcreate", "Routing", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoId Should get %s, instead got %s", expectedUrl, url))
+}
+
+func TestUrlGenerationNoParent(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&percolate=Percolate&refresh=true&routing=Routing&timeout=Timeout&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "", 1, "create", "Routing", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoParent Should get %s, instead got %s", expectedUrl, url))
+}
+
+func TestUrlGenerationNoVersion(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&parent=Parent&percolate=Percolate&refresh=true&routing=Routing&timeout=Timeout&timestamp=TimeStamp&ttl=10"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 0, "create", "Routing", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoVersion Should get %s, instead got %s", expectedUrl, url))
+}
+
+func TestUrlGenerationNoOpType(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?parent=Parent&percolate=Percolate&refresh=true&routing=Routing&timeout=Timeout&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 1, "", "Routing", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoOpType Should get %s, instead got %s", expectedUrl, url))
+}
+func TestUrlGenerationNoRouting(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&parent=Parent&percolate=Percolate&refresh=true&timeout=Timeout&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 1, "create", "", "TimeStamp", 10, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoRouting Should get %s, instead got %s", expectedUrl, url))
+}
+func TestUrlGenerationNoTimestamp(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&parent=Parent&percolate=Percolate&refresh=true&routing=Routing&timeout=Timeout&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 1, "create", "Routing", "", 10, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoTimestamp Should get %s, instead got %s", expectedUrl, url))
+}
+func TestUrlGenerationNoTTL(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&parent=Parent&percolate=Percolate&refresh=true&routing=Routing&timeout=Timeout&timestamp=TimeStamp&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 1, "create", "Routing", "TimeStamp", 0, "Percolate", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoTTL Should get %s, instead got %s", expectedUrl, url))
+}
+func TestUrlGenerationNoPercolate(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&parent=Parent&refresh=true&routing=Routing&timeout=Timeout&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 1, "create", "Routing", "TimeStamp", 10, "", "Timeout", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoPercolate Should get %s, instead got %s", expectedUrl, url))
+}
+func TestUrlGenerationNoTimeout(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&parent=Parent&percolate=Percolate&refresh=true&routing=Routing&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 1, "create", "Routing", "TimeStamp", 10, "Percolate", "", true)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoTimeout Should get %s, instead got %s", expectedUrl, url))
+}
+func TestUrlGenerationNoRefresh(t *testing.T) {
+	expectedUrl := "/Index/Type/Id?op_type=create&parent=Parent&percolate=Percolate&routing=Routing&timeout=Timeout&timestamp=TimeStamp&ttl=10&version=1"
+	url, err := GetIndexUrl("Index", "Type", "Id", "Parent", 1, "create", "Routing", "TimeStamp", 10, "Percolate", "Timeout", false)
+	u.Assert(err == nil, t, "err was not nil")
+	u.Assert(url == expectedUrl, t, fmt.Sprintf("TestUrlGenerationNoRefresh Should get %s, instead got %s", expectedUrl, url))
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/mget.go b/src/github.com/mattbaird/elastigo/core/mget.go
--- a/src/github.com/mattbaird/elastigo/core/mget.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/mget.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,64 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// MGet allows the caller to get multiple documents based on an index, type (optional) and id (and possibly routing).
+// The response includes a docs array with all the fetched documents, each element similar in structure to a document
+// provided by the get API.
+// see http://www.elasticsearch.org/guide/reference/api/multi-get.html
+func MGet(pretty bool, index string, _type string, mgetRequest MGetRequestContainer) (MGetResponseContainer, error) {
+	var url string
+	var retval MGetResponseContainer
+	if len(index) <= 0 {
+		url = fmt.Sprintf("/_mget?%s", api.Pretty(pretty))
+	}
+	if len(_type) > 0 && len(index) > 0 {
+		url = fmt.Sprintf("/%s/%s/_mget?%s", index, _type, api.Pretty(pretty))
+	} else if len(index) > 0 {
+		url = fmt.Sprintf("/%s/_mget?%s", index, api.Pretty(pretty))
+	}
+	body, err := api.DoCommand("GET", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
+
+type MGetRequestContainer struct {
+	Docs []MGetRequest `json:"docs"`
+}
+
+type MGetRequest struct {
+	Index  string   `json:"_index"`
+	Type   string   `json:"_type"`
+	ID     string   `json:"_id"`
+	IDS    []string `json:"_ids,omitempty"`
+	Fields []string `json:"fields,omitempty"`
+}
+
+type MGetResponseContainer struct {
+	Docs []api.BaseResponse `json:"docs"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/moreLikeThis.go b/src/github.com/mattbaird/elastigo/core/moreLikeThis.go
--- a/src/github.com/mattbaird/elastigo/core/moreLikeThis.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/moreLikeThis.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,59 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// MoreLikeThis allows the caller to get documents that are like a specified document.
+// http://www.elasticsearch.org/guide/reference/api/more-like-this.html
+func MoreLikeThis(pretty bool, index string, _type string, id string, query MoreLikeThisQuery) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url = fmt.Sprintf("/%s/%s/%s/_mlt?%s", index, _type, id, api.Pretty(pretty))
+	body, err := api.DoCommand("GET", url, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
+
+type MoreLikeThisQuery struct {
+	MoreLikeThis MLT `json:"more_like_this"`
+}
+
+type MLT struct {
+	Fields              []string `json:"fields"`
+	LikeText            string   `json:"like_text"`
+	PercentTermsToMatch float32  `json:"percent_terms_to_match"`
+	MinTermFrequency    int      `json:"min_term_freq"`
+	MaxQueryTerms       int      `json:"max_query_terms"`
+	StopWords           []string `json:"stop_words"`
+	MinDocFrequency     int      `json:"min_doc_freq"`
+	MaxDocFrequency     int      `json:"max_doc_freq"`
+	MinWordLength       int      `json:"min_word_len"`
+	MaxWordLength       int      `json:"max_word_len"`
+	BoostTerms          int      `json:"boost_terms"`
+	Boost               float32  `json:"boost"`
+	Analyzer            string   `json:"analyzer"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/msearch.go b/src/github.com/mattbaird/elastigo/core/msearch.go
--- a/src/github.com/mattbaird/elastigo/core/msearch.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/msearch.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
diff -ruN a/src/github.com/mattbaird/elastigo/core/percolate.go b/src/github.com/mattbaird/elastigo/core/percolate.go
--- a/src/github.com/mattbaird/elastigo/core/percolate.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/percolate.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,62 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// RegisterPercolate allows the caller to register queries against an index, and then send percolate requests which include a doc, and
+// getting back the queries that match on that doc out of the set of registered queries.
+// Think of it as the reverse operation of indexing and then searching. Instead of sending docs, indexing them,
+// and then running queries. One sends queries, registers them, and then sends docs and finds out which queries
+// match that doc.
+// see http://www.elasticsearch.org/guide/reference/api/percolate.html
+func RegisterPercolate(pretty bool, index string, name string, query api.Query) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url = fmt.Sprintf("/_percolator/%s/%s?%s", index, name, api.Pretty(pretty))
+	body, err := api.DoCommand("PUT", url, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
+
+func Percolate(pretty bool, index string, _type string, name string, doc string) (api.Match, error) {
+	var url string
+	var retval api.Match
+	url = fmt.Sprintf("/%s/%s/_percolate?%s", index, _type, api.Pretty(pretty))
+	body, err := api.DoCommand("GET", url, doc)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/search.go b/src/github.com/mattbaird/elastigo/core/search.go
--- a/src/github.com/mattbaird/elastigo/core/search.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/search.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,168 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"net/url"
+	"strconv"
+)
+
+var (
+	DebugRequests = false
+)
+
+// SearchRequest performs a very basic search on an index via the request URI API.
+//
+// params:
+//   @pretty:  bool for pretty reply or not, a parameter to elasticsearch
+//   @index:  the elasticsearch index
+//   @_type:  optional ("" if not used) search specific type in this index
+//   @query:  this can be one of 3 types:
+//              1)  string value that is valid elasticsearch
+//              2)  io.Reader that can be set in body (also valid elasticsearch string syntax..)
+//              3)  other type marshalable to json (also valid elasticsearch json)
+//
+//   out, err := SearchRequest(true, "github","",qryType ,"", 0)
+//
+// http://www.elasticsearch.org/guide/reference/api/search/uri-request.html
+func SearchRequest(pretty bool, index string, _type string, query interface{}, scroll string, scan int) (SearchResult, error) {
+	var uriVal string
+	var retval SearchResult
+	if len(_type) > 0 && _type != "*" {
+		uriVal = fmt.Sprintf("/%s/%s/_search?%s%s%s", index, _type, api.Pretty(pretty), api.Scroll(scroll), api.Scan(scan))
+	} else {
+		uriVal = fmt.Sprintf("/%s/_search?%s%s%s", index, api.Pretty(pretty), api.Scroll(scroll), api.Scan(scan))
+	}
+	body, err := api.DoCommand("POST", uriVal, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal([]byte(body), &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+// SearchUri performs the simplest possible query in url string
+// params:
+//   @index:  the elasticsearch index
+//   @_type:  optional ("" if not used) search specific type in this index
+//   @query:  valid string lucene search syntax
+//
+//   out, err := SearchUri("github","",`user:kimchy` ,"", 0)
+//
+// produces a request like this:    host:9200/github/_search?q=user:kimchy"
+//
+// http://www.elasticsearch.org/guide/reference/api/search/uri-request.html
+func SearchUri(index, _type string, query, scroll string, scan int) (SearchResult, error) {
+	var uriVal string
+	var retval SearchResult
+	query = url.QueryEscape(query)
+	if len(_type) > 0 && _type != "*" {
+		uriVal = fmt.Sprintf("/%s/%s/_search?q=%s%s%s", index, _type, query, api.Scroll(scroll), api.Scan(scan))
+	} else {
+		uriVal = fmt.Sprintf("/%s/_search?q=%s%s%s", index, query, api.Scroll(scroll), api.Scan(scan))
+	}
+	//log.Println(uriVal)
+	body, err := api.DoCommand("GET", uriVal, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal([]byte(body), &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func Scroll(pretty bool, scroll_id string, scroll string) (SearchResult, error) {
+	var url string
+	var retval SearchResult
+
+	url = fmt.Sprintf("/_search/scroll?%s%s", api.Pretty(pretty), api.Scroll(scroll))
+
+	body, err := api.DoCommand("POST", url, scroll_id)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal([]byte(body), &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type SearchResult struct {
+	Took        int             `json:"took"`
+	TimedOut    bool            `json:"timed_out"`
+	ShardStatus api.Status      `json:"_shards"`
+	Hits        Hits            `json:"hits"`
+	Facets      json.RawMessage `json:"facets,omitempty"` // structure varies on query
+	ScrollId    string          `json:"_scroll_id,omitempty"`
+}
+
+func (s *SearchResult) String() string {
+	return fmt.Sprintf("<Results took=%v Timeout=%v hitct=%v />", s.Took, s.TimedOut, s.Hits.Total)
+}
+
+type Hits struct {
+	Total int `json:"total"`
+	//	MaxScore float32 `json:"max_score"`
+	Hits []Hit `json:"hits"`
+}
+
+func (h *Hits) Len() int {
+	return len(h.Hits)
+}
+
+type Hit struct {
+	Index  string          `json:"_index"`
+	Type   string          `json:"_type,omitempty"`
+	Id     string          `json:"_id"`
+	Score  Float32Nullable `json:"_score,omitempty"` // Filters (no query) dont have score, so is null
+	Source json.RawMessage `json:"_source"`          // marshalling left to consumer
+	Fields json.RawMessage `json:"fields"`           // when a field arg is passed to ES, instead of _source it returns fields
+}
+
+// Elasticsearch returns some invalid (according to go) json, with floats having...
+//
+// json: cannot unmarshal null into Go value of type float32 (see last field.)
+//
+// "hits":{"total":6808,"max_score":null,
+//    "hits":[{"_index":"10user","_type":"user","_id":"751820","_score":null,
+type Float32Nullable float32
+
+func (i *Float32Nullable) UnmarshalJSON(data []byte) error {
+	if len(data) == 0 || string(data) == "null" {
+		return nil
+	}
+
+	if in, err := strconv.ParseFloat(string(data), 32); err != nil {
+		return err
+	} else {
+		*i = Float32Nullable(in)
+	}
+	return nil
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/search_test.go b/src/github.com/mattbaird/elastigo/core/search_test.go
--- a/src/github.com/mattbaird/elastigo/core/search_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/search_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,30 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	u "github.com/araddon/gou"
+	"testing"
+)
+
+func TestSearchRequest(t *testing.T) {
+	qry := map[string]interface{}{
+		"query": map[string]interface{}{
+			"wildcard": map[string]string{"actor": "a*"},
+		},
+	}
+	out, err := SearchRequest(true, "github", "", qry, "", 0)
+	//log.Println(out)
+	Assert(&out != nil && err == nil, t, "Should get docs")
+	Assert(out.Hits.Len() == 10, t, "Should have 10 docs but was %v", out.Hits.Len())
+	Assert(u.CloseInt(out.Hits.Total, 588), t, "Should have 588 hits but was %v", out.Hits.Total)
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/test_test.go b/src/github.com/mattbaird/elastigo/core/test_test.go
--- a/src/github.com/mattbaird/elastigo/core/test_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/test_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,192 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"bufio"
+	"bytes"
+	"compress/gzip"
+	"crypto/md5"
+	"encoding/json"
+	"flag"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"io"
+	"log"
+	"net/http"
+	"os"
+	"testing"
+	"time"
+)
+
+/*
+
+usage:
+
+	test -v -host eshost -loaddata
+
+*/
+
+var (
+	_                 = os.ModeDir
+	bulkStarted       bool
+	hasLoadedData     bool
+	hasStartedTesting bool
+	eshost            *string = flag.String("host", "localhost", "Elasticsearch Server Host Address")
+	loadData          *bool   = flag.Bool("loaddata", false, "This loads a bunch of test data into elasticsearch for testing")
+)
+
+func init() {
+
+}
+func InitTests(startIndexer bool) {
+	if !hasStartedTesting {
+		flag.Parse()
+		hasStartedTesting = true
+		log.SetFlags(log.Ltime | log.Lshortfile)
+		api.Domain = *eshost
+	}
+	if startIndexer && !bulkStarted {
+		BulkDelaySeconds = 1
+		bulkStarted = true
+		log.Println("start global test bulk indexer")
+		BulkIndexerGlobalRun(100, make(chan bool))
+		if *loadData && !hasLoadedData {
+			log.Println("load test data ")
+			hasLoadedData = true
+			LoadTestData()
+		}
+	}
+}
+
+// dumb simple assert for testing, printing
+//    Assert(len(items) == 9, t, "Should be 9 but was %d", len(items))
+func Assert(is bool, t *testing.T, format string, args ...interface{}) {
+	if is == false {
+		log.Printf(format, args...)
+		t.Fail()
+	}
+}
+
+// Wait for condition (defined by func) to be true, a utility to create a ticker
+// checking every 100 ms to see if something (the supplied check func) is done
+//
+//   WaitFor(func() bool {
+//      return ctr.Ct == 0
+//   },10)
+//
+// @timeout (in seconds) is the last arg
+func WaitFor(check func() bool, timeoutSecs int) {
+	timer := time.NewTicker(100 * time.Millisecond)
+	tryct := 0
+	for _ = range timer.C {
+		if check() {
+			timer.Stop()
+			break
+		}
+		if tryct >= timeoutSecs*10 {
+			timer.Stop()
+			break
+		}
+		tryct++
+	}
+}
+
+func TestFake(t *testing.T) {
+
+}
+
+type GithubEvent struct {
+	Url     string
+	Created time.Time `json:"created_at"`
+	Type    string
+}
+
+// This loads test data from github archives (~6700 docs)
+func LoadTestData() {
+	docCt := 0
+	errCt := 0
+	indexer := NewBulkIndexer(20)
+	indexer.BulkSendor = func(buf *bytes.Buffer) error {
+		log.Printf("Sent %d bytes total %d docs sent", buf.Len(), docCt)
+		req, err := api.ElasticSearchRequest("POST", "/_bulk")
+		if err != nil {
+			errCt += 1
+			log.Println("ERROR: ", err)
+			return err
+		}
+		req.SetBody(buf)
+		res, err := http.DefaultClient.Do((*http.Request)(req))
+		if err != nil {
+			errCt += 1
+			log.Println("ERROR: ", err)
+			return err
+		}
+		if res.StatusCode != 200 {
+			log.Printf("Not 200! %d \n", res.StatusCode)
+		}
+		return err
+	}
+	done := make(chan bool)
+	indexer.Run(done)
+	resp, err := http.Get("http://data.githubarchive.org/2012-12-10-15.json.gz")
+	if err != nil || resp == nil {
+		panic("Could not download data")
+	}
+	defer resp.Body.Close()
+	if err != nil {
+		log.Println(err)
+		return
+	}
+	gzReader, err := gzip.NewReader(resp.Body)
+	defer gzReader.Close()
+	if err != nil {
+		panic(err)
+	}
+	r := bufio.NewReader(gzReader)
+	var ge GithubEvent
+	docsm := make(map[string]bool)
+	h := md5.New()
+	for {
+		line, err := r.ReadBytes('\n')
+		if err != nil && err != io.EOF {
+			log.Println("FATAL:  could not read line? ", err)
+		} else if err != nil {
+			indexer.Flush()
+			break
+		}
+		if err := json.Unmarshal(line, &ge); err == nil {
+			// create an "ID"
+			h.Write(line)
+			id := fmt.Sprintf("%x", h.Sum(nil))
+			if _, ok := docsm[id]; ok {
+				log.Println("HM, already exists? ", ge.Url)
+			}
+			docsm[id] = true
+			indexer.Index("github", ge.Type, id, "", &ge.Created, line)
+			docCt++
+			//log.Println(docCt, " ", string(line))
+			//os.Exit(1)
+		} else {
+			log.Println("ERROR? ", string(line))
+		}
+
+	}
+	if errCt != 0 {
+		log.Println("FATAL, could not load ", errCt)
+	}
+	// lets wait a bit to ensure that elasticsearch finishes?
+	time.Sleep(time.Second * 5)
+	if len(docsm) != docCt {
+		panic(fmt.Sprintf("Docs didn't match?   %d:%d", len(docsm), docCt))
+	}
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/update.go b/src/github.com/mattbaird/elastigo/core/update.go
--- a/src/github.com/mattbaird/elastigo/core/update.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/update.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,97 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// Update updates a document based on a script provided. The operation gets the document
+// (collocated with the shard) from the index, runs the script (with optional script language and parameters),
+// and index back the result (also allows to delete, or ignore the operation). It uses versioning to make sure
+// no updates have happened during the get and reindex. (available from 0.19 onwards).
+// Note, this operation still means full reindex of the document, it just removes some network roundtrips
+// and reduces chances of version conflicts between the get and the index. The _source field need to be enabled
+// for this feature to work.
+//
+// http://www.elasticsearch.org/guide/reference/api/update.html
+// TODO: finish this, it's fairly complex
+func Update(pretty bool, index string, _type string, id string, data interface{}) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url = fmt.Sprintf("/%s/%s/%s/_update?%s", index, _type, id, api.Pretty(pretty))
+	body, err := api.DoCommand("POST", url, data)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
+
+// UpdateWithPartialDoc updates a document based on partial document provided. The update API also 
+// support passing a partial document (since 0.20), which will be merged into the existing 
+// document (simple recursive merge, inner merging of objects, replacing core "keys/values" and arrays). 
+// If both doc and script is specified, then doc is ignored. Best is to put your field pairs of the partial 
+// document in the script itself.
+//
+// http://www.elasticsearch.org/guide/reference/api/update.html
+func UpdateWithPartialDoc(pretty bool, index string, _type string, id string, doc interface{}, upsert bool) (api.BaseResponse, error) {
+	switch v := doc.(type) {
+	case string:
+		upsertStr := ""
+		if upsert {
+			upsertStr = ", \"doc_as_upsert\":true"
+		}
+		content := fmt.Sprintf("{\"doc\":%s %s}", v, upsertStr)
+		return Update(pretty, index, _type, id, content)
+	default:
+		var data map[string]interface{} = make(map[string]interface{})
+		data["doc"] = doc
+		if upsert {
+			data["doc_as_upsert"] = true
+		}
+		return Update(pretty, index, _type, id, data)
+	}
+}
+
+// UpdateWithScript updates a document based on a script provided.	
+// The operation gets the document (collocated with the shard) from the index, runs the script 
+// (with optional script language and parameters), and index back the result (also allows to 
+// delete, or ignore the operation). It uses versioning to make sure no updates have happened 
+// during the "get" and "reindex". (available from 0.19 onwards).
+// 
+// Note, this operation still means full reindex of the document, it just removes some network 
+// roundtrips and reduces chances of version conflicts between the get and the index. The _source 
+// field need to be enabled for this feature to work.
+// http://www.elasticsearch.org/guide/reference/api/update.html
+func UpdateWithScript(pretty bool, index string, _type string, id string, script string, params interface{}) (api.BaseResponse, error) {
+	switch v := params.(type) {
+	case string:
+		paramsPart := fmt.Sprintf("{\"params\":%s}", v)
+		data := fmt.Sprintf("{\"script\":\"%s\", \"params\":%s}", script, paramsPart)
+		return Update(pretty, index, _type, id, data)
+	default:
+		var data map[string]interface{} = make(map[string]interface{})
+		data["params"] = params
+		data["script"] = script
+		return Update(pretty, index, _type, id, data)
+	}
+}
diff -ruN a/src/github.com/mattbaird/elastigo/core/validate.go b/src/github.com/mattbaird/elastigo/core/validate.go
--- a/src/github.com/mattbaird/elastigo/core/validate.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/core/validate.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,55 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+)
+
+// Validate allows a user to validate a potentially expensive query without executing it.
+// see http://www.elasticsearch.org/guide/reference/api/validate.html
+func Validate(pretty bool, index string, _type string, query string, explain bool) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/_validate/query?q=%s&%s&explain=%t", index, _type, query, api.Pretty(pretty), explain)
+	} else {
+		url = fmt.Sprintf("/%s/_validate/query?q=%s&%s&explain=%t", index, query, api.Pretty(pretty), explain)
+	}
+	body, err := api.DoCommand("GET", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	fmt.Println(body)
+	return retval, err
+}
+
+type Validation struct {
+	Valid         bool           `json:"valid"`
+	Shards        api.Status     `json:"_shards"`
+	Explainations []Explaination `json:"explanations,omitempty"`
+}
+
+type Explaination struct {
+	Index string `json:"index"`
+	Valid bool   `json:"valid"`
+	Error string `json:"error"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/doc.go b/src/github.com/mattbaird/elastigo/doc.go
--- a/src/github.com/mattbaird/elastigo/doc.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/doc.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,15 @@
+// Copyright 2012 Matthew Baird
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package main
Binary files a/src/github.com/mattbaird/elastigo/elastigo and b/src/github.com/mattbaird/elastigo/elastigo differ
diff -ruN a/src/github.com/mattbaird/elastigo/indices/aliases.go b/src/github.com/mattbaird/elastigo/indices/aliases.go
--- a/src/github.com/mattbaird/elastigo/indices/aliases.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/aliases.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/analyze.go b/src/github.com/mattbaird/elastigo/indices/analyze.go
--- a/src/github.com/mattbaird/elastigo/indices/analyze.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/analyze.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,74 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"net/url"
+	"strings"
+)
+
+// AnalyzeIndices performs the analysis process on a text and return the tokens breakdown of the text.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-analyze/
+func AnalyzeIndices(index string, analyzer string, tokenizer string, field string, text string, filters ...string) (AnalyzeResponse, error) {
+	var retval AnalyzeResponse
+	if len(text) <= 0 {
+		return retval, errors.New("text to analyze must not be blank")
+	}
+	var analyzeUrl string = "/_analyze"
+	if len(index) > 0 {
+		analyzeUrl = fmt.Sprintf("/%s/%s", index, analyzeUrl)
+	}
+	var values url.Values = url.Values{}
+	if len(analyzer) > 0 {
+		values.Add("analyzer", analyzer)
+	}
+	if len(tokenizer) > 0 {
+		values.Add("tokenizer", tokenizer)
+	}
+	if len(field) > 0 {
+		values.Add("field", field)
+	}
+	if len(filters) > 0 {
+		values.Add("filters", strings.Join(filters, ","))
+	}
+	// text will not be blank
+	values.Add("text", text)
+	analyzeUrl += "?" + values.Encode()
+
+	body, err := api.DoCommand("GET", analyzeUrl, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type AnalyzeResponse struct {
+	Tokens []Token `json:"tokens"`
+}
+type Token struct {
+	Name        string `json:"token"`
+	StartOffset string `json:"start_offset"`
+	EndOffset   string `json:"end_offset"`
+	Type        string `json:"type"`
+	Position    string `json:"position"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/indices/clearCache.go b/src/github.com/mattbaird/elastigo/indices/clearCache.go
--- a/src/github.com/mattbaird/elastigo/indices/clearCache.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/clearCache.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,54 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"net/url"
+	"strings"
+)
+
+// ClearCache allows to clear either all caches or specific cached associated with one ore more indices.
+// see http://www.elasticsearch.org/guide/reference/api/admin-indices-clearcache/
+func ClearCache(clearId bool, clearBloom bool, indices ...string) (api.ExtendedStatus, error) {
+	var retval api.ExtendedStatus
+	var clearCacheUrl string
+	if len(indices) > 0 {
+		clearCacheUrl = fmt.Sprintf("/%s/_cache/clear", strings.Join(indices, ","))
+
+	} else {
+		clearCacheUrl = fmt.Sprintf("/_cache/clear")
+	}
+	var values url.Values = url.Values{}
+
+	if clearId {
+		values.Add("id", "true")
+	}
+	if clearBloom {
+		values.Add("bloom", "true")
+	}
+	clearCacheUrl += "?" + values.Encode()
+	body, err := api.DoCommand("POST", clearCacheUrl, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/indices/createIndex.go b/src/github.com/mattbaird/elastigo/indices/createIndex.go
--- a/src/github.com/mattbaird/elastigo/indices/createIndex.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/createIndex.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/deleteIndex.go b/src/github.com/mattbaird/elastigo/indices/deleteIndex.go
--- a/src/github.com/mattbaird/elastigo/indices/deleteIndex.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/deleteIndex.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/deleteMapping.go b/src/github.com/mattbaird/elastigo/indices/deleteMapping.go
--- a/src/github.com/mattbaird/elastigo/indices/deleteMapping.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/deleteMapping.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/doc.go b/src/github.com/mattbaird/elastigo/indices/doc.go
--- a/src/github.com/mattbaird/elastigo/indices/doc.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/doc.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/flush.go b/src/github.com/mattbaird/elastigo/indices/flush.go
--- a/src/github.com/mattbaird/elastigo/indices/flush.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/flush.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,48 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"strings"
+)
+
+// Flush flushes one or more indices through an API. The flush process of an index basically
+// frees memory from the index by flushing data to the index storage and clearing the internal transaction
+// log. By default, ElasticSearch uses memory heuristics in order to automatically trigger flush operations
+// as required in order to clear memory.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-flush.html
+// TODO: add Shards to response
+func Flush(indices ...string) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_flush", strings.Join(indices, ","))
+	} else {
+		url = "/_flush"
+	}
+	body, err := api.DoCommand("POST", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	//fmt.Println(body)
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/indices/getSettings.go b/src/github.com/mattbaird/elastigo/indices/getSettings.go
--- a/src/github.com/mattbaird/elastigo/indices/getSettings.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/getSettings.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/indicesExists.go b/src/github.com/mattbaird/elastigo/indices/indicesExists.go
--- a/src/github.com/mattbaird/elastigo/indices/indicesExists.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/indicesExists.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,37 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"strings"
+)
+
+// IndicesExists checks for the existance of indices. uses http 404 if it does not exist, and 200 if it does
+// see http://www.elasticsearch.org/guide/reference/api/admin-indices-indices-exists/
+func IndicesExists(indices ...string) (bool, error) {
+	var url string
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s", strings.Join(indices, ","))
+	}
+	_, err := api.DoCommand("HEAD", url, nil)
+	if err != nil {
+		eserror := err.(api.ESError)
+		if eserror.Code == 404 {
+			return false, err
+		} else {
+			return eserror.Code == 200, err
+		}
+	}
+	return true, nil
+}
diff -ruN a/src/github.com/mattbaird/elastigo/indices/openCloseIndex.go b/src/github.com/mattbaird/elastigo/indices/openCloseIndex.go
--- a/src/github.com/mattbaird/elastigo/indices/openCloseIndex.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/openCloseIndex.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/optimize.go b/src/github.com/mattbaird/elastigo/indices/optimize.go
--- a/src/github.com/mattbaird/elastigo/indices/optimize.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/optimize.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,68 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"net/url"
+	"strconv"
+	"strings"
+)
+
+// AnalyzeIndices performs the analysis process on a text and return the tokens breakdown of the text.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-analyze/
+func OptimizeIndices(max_num_segments int, only_expunge_deletes bool, refresh bool, flush bool, wait_for_merge bool,
+	indices ...string) (OptimizeResponse, error) {
+	var retval OptimizeResponse
+	var optimizeUrl string = "/_optimize"
+	if len(indices) > 0 {
+		optimizeUrl = fmt.Sprintf("/%s/%s", strings.Join(indices, ","), optimizeUrl)
+	}
+	var values url.Values = url.Values{}
+	if max_num_segments > 0 {
+		values.Add("max_num_segments", strconv.Itoa(max_num_segments))
+	}
+	if only_expunge_deletes {
+		values.Add("only_expunge_deletes", strconv.FormatBool(only_expunge_deletes))
+	}
+	if !refresh {
+		values.Add("refresh", strconv.FormatBool(refresh))
+	}
+	if !flush {
+		values.Add("flush", strconv.FormatBool(flush))
+	}
+	if wait_for_merge {
+		values.Add("wait_for_merge", strconv.FormatBool(wait_for_merge))
+	}
+
+	optimizeUrl += "?" + values.Encode()
+
+	body, err := api.DoCommand("POST", optimizeUrl, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type OptimizeResponse struct {
+	Ok     bool       `json:"ok"`
+	Shards api.Status `json:"_shards"`
+}
diff -ruN a/src/github.com/mattbaird/elastigo/indices/putMapping.go b/src/github.com/mattbaird/elastigo/indices/putMapping.go
--- a/src/github.com/mattbaird/elastigo/indices/putMapping.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/putMapping.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/refresh.go b/src/github.com/mattbaird/elastigo/indices/refresh.go
--- a/src/github.com/mattbaird/elastigo/indices/refresh.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/refresh.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,46 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"strings"
+)
+
+// Refresh explicitly refreshes one or more index, making all operations performed since
+// the last refresh available for search. The (near) real-time capabilities depend on the index engine used.
+// For example, the robin one requires refresh to be called, but by default a refresh is scheduled periodically.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-refresh.html
+// TODO: add Shards to response
+func Refresh(indices ...string) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_refresh", strings.Join(indices, ","))
+	} else {
+		url = "/_refresh"
+	}
+	body, err := api.DoCommand("POST", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/indices/segments.go b/src/github.com/mattbaird/elastigo/indices/segments.go
--- a/src/github.com/mattbaird/elastigo/indices/segments.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/segments.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/snapshot.go b/src/github.com/mattbaird/elastigo/indices/snapshot.go
--- a/src/github.com/mattbaird/elastigo/indices/snapshot.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/snapshot.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,45 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"strings"
+)
+
+// Snapshot  allows to explicitly perform a snapshot through the gateway of one or more indices (backup them).
+// By default, each index gateway periodically snapshot changes, though it can be disabled and be controlled completely through this API.
+// see http://www.elasticsearch.org/guide/reference/api/admin-indices-gateway-snapshot/
+func Snapshot(indices ...string) (api.ExtendedStatus, error) {
+	var retval api.ExtendedStatus
+	var url string
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_gateway/snapshot", strings.Join(indices, ","))
+
+	} else {
+		url = fmt.Sprintf("/_gateway/snapshot")
+	}
+	body, err := api.DoCommand("POST", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/indices/stats.go b/src/github.com/mattbaird/elastigo/indices/stats.go
--- a/src/github.com/mattbaird/elastigo/indices/stats.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/stats.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/status.go b/src/github.com/mattbaird/elastigo/indices/status.go
--- a/src/github.com/mattbaird/elastigo/indices/status.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/status.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,44 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"strings"
+)
+
+// Status lists status details of all indices or the specified index.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-status.html
+func Status(pretty bool, indices ...string) (api.BaseResponse, error) {
+	var retval api.BaseResponse
+	var url string
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_status?%s", strings.Join(indices, ","), api.Pretty(pretty))
+
+	} else {
+		url = fmt.Sprintf("/_status?%s", api.Pretty(pretty))
+	}
+	body, err := api.DoCommand("GET", url, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -ruN a/src/github.com/mattbaird/elastigo/indices/templates.go b/src/github.com/mattbaird/elastigo/indices/templates.go
--- a/src/github.com/mattbaird/elastigo/indices/templates.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/templates.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/indices/updateSettings.go b/src/github.com/mattbaird/elastigo/indices/updateSettings.go
--- a/src/github.com/mattbaird/elastigo/indices/updateSettings.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/indices/updateSettings.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -ruN a/src/github.com/mattbaird/elastigo/search/README b/src/github.com/mattbaird/elastigo/search/README
--- a/src/github.com/mattbaird/elastigo/search/README	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/README	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,4 @@
+
+
+To run tests on this, you must first have run/imported data inside of *core*
+
diff -ruN a/src/github.com/mattbaird/elastigo/search/facet.go b/src/github.com/mattbaird/elastigo/search/facet.go
--- a/src/github.com/mattbaird/elastigo/search/facet.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/facet.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,81 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+
+	u "github.com/araddon/gou"
+)
+
+var (
+	_ = u.DEBUG
+)
+
+/*
+"facets": {
+    "terms": {
+		"terms": {
+			"field": [
+			  "@fields.category"
+			],
+			"size": 25
+		}
+    }
+}
+
+
+"facets": {
+  "actors": { "terms": {"field": ["actor"],"size": "10" }}
+  , "langauge": { "terms": {"field": ["repository.language"],"size": "10" }}
+}
+
+*/
+func Facet() *FacetDsl {
+	return &FacetDsl{}
+}
+
+type FacetDsl struct {
+	size  string
+	Terms map[string]*Term `json:"terms,omitempty"`
+}
+
+func (m *FacetDsl) Size(size string) *FacetDsl {
+	m.size = size
+	return m
+}
+
+func (m *FacetDsl) Regex(field, match string) *FacetDsl {
+	if len(m.Terms) == 0 {
+		m.Terms = make(map[string]*Term)
+	}
+	m.Terms[field] = &Term{Terms{Fields: []string{field}, Regex: match}}
+	return m
+}
+
+func (m *FacetDsl) Fields(fields ...string) *FacetDsl {
+	if len(fields) < 1 {
+		return m
+	}
+	if len(m.Terms) == 0 {
+		m.Terms = make(map[string]*Term)
+	}
+	m.Terms[fields[0]] = &Term{Terms{Fields: fields}}
+	return m
+}
+
+func (m *FacetDsl) MarshalJSON() ([]byte, error) {
+	for _, t := range m.Terms {
+		t.Terms.Size = m.size
+	}
+	return json.Marshal(&m.Terms)
+}
diff -ruN a/src/github.com/mattbaird/elastigo/search/facet_test.go b/src/github.com/mattbaird/elastigo/search/facet_test.go
--- a/src/github.com/mattbaird/elastigo/search/facet_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/facet_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,37 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	//"encoding/json"
+	. "github.com/araddon/gou"
+	"testing"
+)
+
+func TestFacetRegex(t *testing.T) {
+
+	// This is a possible solution for auto-complete
+	out, _ := Search("github").Size("0").Facet(
+		Facet().Regex("repository.name", "no.*").Size("8"),
+	).Result()
+	if out == nil || &out.Hits == nil {
+		t.Fail()
+		return
+	}
+	//Debug(string(out.Facets))
+	fh := NewJsonHelper([]byte(out.Facets))
+	facets := fh.Helpers("/repository.name/terms")
+	Assert(len(facets) == 8, t, "Should have 8? but was %v", len(facets))
+	// for _, f := range facets {
+	// 	Debug(f)
+	// }
+}
diff -ruN a/src/github.com/mattbaird/elastigo/search/filter.go b/src/github.com/mattbaird/elastigo/search/filter.go
--- a/src/github.com/mattbaird/elastigo/search/filter.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/filter.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,200 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+	"fmt"
+
+	. "github.com/araddon/gou"
+)
+
+var (
+	_ = DEBUG
+)
+
+// A bool (and/or) clause
+type BoolClause string
+
+// Filter clause is either a boolClause or FilterOp
+type FilterClause interface {
+	String() string
+}
+
+// A wrapper to allow for custom serialization
+type FilterWrap struct {
+	boolClause string
+	filters    []interface{}
+}
+
+func NewFilterWrap() *FilterWrap {
+	return &FilterWrap{filters: make([]interface{}, 0), boolClause: "and"}
+}
+
+func (f *FilterWrap) String() string {
+	return fmt.Sprintf(`fopv: %d:%v`, len(f.filters), f.filters)
+}
+
+// Custom marshalling to support the query dsl
+func (f *FilterWrap) addFilters(fl []interface{}) {
+	if len(fl) > 1 {
+		fc := fl[0]
+		switch fc.(type) {
+		case BoolClause, string:
+			f.boolClause = fc.(string)
+			fl = fl[1:]
+		}
+	}
+	f.filters = append(f.filters, fl...)
+}
+
+// Custom marshalling to support the query dsl
+func (f *FilterWrap) MarshalJSON() ([]byte, error) {
+	var root interface{}
+	if len(f.filters) > 1 {
+		root = map[string]interface{}{f.boolClause: f.filters}
+	} else if len(f.filters) == 1 {
+		root = f.filters[0]
+	}
+	return json.Marshal(root)
+}
+
+/*
+	"filter": {
+		"range": {
+		  "@timestamp": {
+		    "from": "2012-12-29T16:52:48+00:00",
+		    "to": "2012-12-29T17:52:48+00:00"
+		  }
+		}
+	}
+	"filter": {
+	    "missing": {
+	        "field": "repository.name"
+	    }
+	}
+
+	"filter" : {
+	    "terms" : {
+	        "user" : ["kimchy", "elasticsearch"],
+	        "execution" : "bool",
+	        "_cache": true
+	    }
+	}
+
+	"filter" : {
+	    "term" : { "user" : "kimchy"}
+	}
+
+	"filter" : {
+	    "and" : [
+	        {
+	            "range" : {
+	                "postDate" : {
+	                    "from" : "2010-03-01",
+	                    "to" : "2010-04-01"
+	                }
+	            }
+	        },
+	        {
+	            "prefix" : { "name.second" : "ba" }
+	        }
+	    ]
+	}
+
+*/
+
+// Filter Operation
+//
+//   Filter().Term("user","kimchy")
+//
+//   // we use variadics to allow n arguments, first is the "field" rest are values
+//   Filter().Terms("user", "kimchy", "elasticsearch")
+//
+//   Filter().Exists("repository.name")
+//
+func Filter() *FilterOp {
+	return &FilterOp{}
+}
+
+type FilterOp struct {
+	curField    string
+	TermsMap    map[string][]interface{}     `json:"terms,omitempty"`
+	Range       map[string]map[string]string `json:"range,omitempty"`
+	Exist       map[string]string            `json:"exists,omitempty"`
+	MisssingVal map[string]string            `json:"missing,omitempty"`
+}
+
+// A range is a special type of Filter operation
+//
+//    Range().Exists("repository.name")
+func Range() *FilterOp {
+	return &FilterOp{Range: make(map[string]map[string]string)}
+}
+
+func (f *FilterOp) Field(fld string) *FilterOp {
+	f.curField = fld
+	if _, ok := f.Range[fld]; !ok {
+		m := make(map[string]string)
+		f.Range[fld] = m
+	}
+	return f
+}
+
+// Filter Terms
+//
+//   Filter().Terms("user","kimchy")
+//
+//   // we use variadics to allow n arguments, first is the "field" rest are values
+//   Filter().Terms("user", "kimchy", "elasticsearch")
+//
+func (f *FilterOp) Terms(field string, values ...interface{}) *FilterOp {
+	if len(f.TermsMap) == 0 {
+		f.TermsMap = make(map[string][]interface{})
+	}
+	for _, val := range values {
+		f.TermsMap[field] = append(f.TermsMap[field], val)
+	}
+
+	return f
+}
+func (f *FilterOp) From(from string) *FilterOp {
+	f.Range[f.curField]["from"] = from
+	return f
+}
+func (f *FilterOp) To(to string) *FilterOp {
+	f.Range[f.curField]["to"] = to
+	return f
+}
+func (f *FilterOp) Exists(name string) *FilterOp {
+	f.Exist = map[string]string{"field": name}
+	return f
+}
+func (f *FilterOp) Missing(name string) *FilterOp {
+	f.MisssingVal = map[string]string{"field": name}
+	return f
+}
+
+// Add another Filterop, "combines" two filter ops into one
+func (f *FilterOp) Add(fop *FilterOp) *FilterOp {
+	// TODO, this is invalid, refactor
+	if len(fop.Exist) > 0 {
+		f.Exist = fop.Exist
+	}
+	if len(fop.MisssingVal) > 0 {
+		f.MisssingVal = fop.MisssingVal
+	}
+	if len(fop.Range) > 0 {
+		f.Range = fop.Range
+	}
+	return f
+}
diff -ruN a/src/github.com/mattbaird/elastigo/search/filter_test.go b/src/github.com/mattbaird/elastigo/search/filter_test.go
--- a/src/github.com/mattbaird/elastigo/search/filter_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/filter_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,96 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	//"encoding/json"
+	. "github.com/araddon/gou"
+	"testing"
+)
+
+func TestFilters(t *testing.T) {
+	// search for docs that are missing repository.name
+	qry := Search("github").Filter(
+		Filter().Exists("repository.name"),
+	)
+	out, err := qry.Result()
+	Assert(err == nil, t, "should not have error")
+	Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	Assert(out.Hits.Total == 7695, t, "Should have 7695 total= %v", out.Hits.Total)
+
+	qry = Search("github").Filter(
+		Filter().Missing("repository.name"),
+	)
+	out, _ = qry.Result()
+	Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	Assert(out.Hits.Total == 389, t, "Should have 389 total= %v", out.Hits.Total)
+
+	//actor_attributes: {type: "User",
+	qry = Search("github").Filter(
+		Filter().Terms("actor_attributes.location", "portland"),
+	)
+	out, _ = qry.Result()
+	Debug(out)
+	Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	Assert(out.Hits.Total == 71, t, "Should have 71 total= %v", out.Hits.Total)
+
+	/*
+		Should this be an AND by default?
+	*/
+	qry = Search("github").Filter(
+		Filter().Terms("actor_attributes.location", "portland"),
+		Filter().Terms("repository.has_wiki", true),
+	)
+	out, err = qry.Result()
+	Debug(out)
+	Assert(err == nil, t, "should not have error")
+	Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	Assert(out.Hits.Total == 44, t, "Should have 44 total= %v", out.Hits.Total)
+
+	// NOW, lets try with two query calls instead of one
+	qry = Search("github").Filter(
+		Filter().Terms("actor_attributes.location", "portland"),
+	)
+	qry.Filter(
+		Filter().Terms("repository.has_wiki", true),
+	)
+	out, err = qry.Result()
+	Debug(out)
+	Assert(err == nil, t, "should not have error")
+	Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	Assert(out.Hits.Total == 44, t, "Should have 44 total= %v", out.Hits.Total)
+
+	qry = Search("github").Filter(
+		"or",
+		Filter().Terms("actor_attributes.location", "portland"),
+		Filter().Terms("repository.has_wiki", true),
+	)
+	out, err = qry.Result()
+	Assert(err == nil, t, "should not have error")
+	Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	Assert(out.Hits.Total == 6676, t, "Should have 6676 total= %v", out.Hits.Total)
+}
+
+func TestFilterRange(t *testing.T) {
+
+	// now lets filter range for repositories with more than 100 forks
+	out, _ := Search("github").Size("25").Filter(
+		Range().Field("repository.forks").From("100"),
+	).Result()
+	if out == nil || &out.Hits == nil {
+		t.Fail()
+		return
+	}
+
+	Assert(out.Hits.Len() == 25, t, "Should have 25 docs %v", out.Hits.Len())
+	Assert(out.Hits.Total == 725, t, "Should have total=725 but was %v", out.Hits.Total)
+}
diff -ruN a/src/github.com/mattbaird/elastigo/search/query.go b/src/github.com/mattbaird/elastigo/search/query.go
--- a/src/github.com/mattbaird/elastigo/search/query.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/query.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,214 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+	"fmt"
+	//"log"
+	"strings"
+)
+
+// QueryDsl creates a new Query Dsl
+func Query() *QueryDsl {
+	return &QueryDsl{}
+}
+
+/*
+
+some ways to serialize
+"query": {
+	"filtered": {
+	  "query": {
+	    "query_string": {
+	      "default_operator": "OR",
+	      "default_field": "_all",
+	      "query": " actor:\"bob\"  AND type:\"EventType\""
+	    }
+	  },
+	  "filter": {
+	    "range": {
+	      "@timestamp": {
+	        "from": "2012-12-29T16:52:48+00:00",
+	        "to": "2012-12-29T17:52:48+00:00"
+	      }
+	    }
+	  }
+	}
+},
+
+"query" : {
+    "term" : { "user" : "kimchy" }
+}
+
+"query" : {
+    "match_all" : {}
+},
+*/
+type QueryDsl struct {
+	QueryEmbed
+	FilterVal *FilterOp `json:"filter,omitempty"`
+}
+
+// The core Query Syntax can be embedded as a child of a variety of different parents
+type QueryEmbed struct {
+	MatchAll *MatchAll         `json:"match_all,omitempty"`
+	Terms    map[string]string `json:"term,omitempty"`
+	Qs       *QueryString      `json:"query_string,omitempty"`
+	//Exist    string            `json:"_exists_,omitempty"`
+}
+
+// MarshalJSON provides custom marshalling to support the query dsl which is a conditional
+// json format, not always the same parent/children
+func (qd *QueryDsl) MarshalJSON() ([]byte, error) {
+	q := qd.QueryEmbed
+	hasQuery := false
+	if q.Qs != nil || len(q.Terms) > 0 || q.MatchAll != nil {
+		hasQuery = true
+	}
+	// If a query has a
+	if qd.FilterVal != nil && hasQuery {
+		queryB, err := json.Marshal(q)
+		if err != nil {
+			return queryB, err
+		}
+		filterB, err := json.Marshal(qd.FilterVal)
+		if err != nil {
+			return filterB, err
+		}
+		return []byte(fmt.Sprintf(`{"filtered":{"query":%s,"filter":%s}}`, queryB, filterB)), nil
+	}
+	return json.Marshal(q)
+}
+
+// get all
+func (q *QueryDsl) All() *QueryDsl {
+	q.MatchAll = &MatchAll{""}
+	return q
+}
+
+// Limit the query to this range
+func (q *QueryDsl) Range(fop *FilterOp) *QueryDsl {
+	if q.FilterVal == nil {
+		q.FilterVal = fop
+		return q
+	}
+	// TODO:  this is not valid, refactor
+	q.FilterVal.Add(fop)
+	return q
+}
+
+// Add a term search for a specific field
+//    Term("user","kimchy")
+func (q *QueryDsl) Term(name, value string) *QueryDsl {
+	if len(q.Terms) == 0 {
+		q.Terms = make(map[string]string)
+	}
+	q.Terms[name] = value
+	return q
+}
+
+// The raw search strings (lucene valid)
+func (q *QueryDsl) Search(searchFor string) *QueryDsl {
+	//I don't think this is right, it is not a filter.query, it should be q query?
+	qs := NewQueryString("", "")
+	q.QueryEmbed.Qs = &qs
+	q.QueryEmbed.Qs.Query = searchFor
+	return q
+}
+
+// Querystring operations
+func (q *QueryDsl) Qs(qs *QueryString) *QueryDsl {
+	q.QueryEmbed.Qs = qs
+	return q
+}
+
+// Fields in query_string search
+//     Fields("fieldname","search_for","","")
+//
+//     Fields("fieldname,field2,field3","search_for","","")
+//
+//     Fields("fieldname,field2,field3","search_for","field_exists","")
+func (q *QueryDsl) Fields(fields, search, exists, missing string) *QueryDsl {
+	fieldList := strings.Split(fields, ",")
+	qs := NewQueryString("", "")
+	q.QueryEmbed.Qs = &qs
+	q.QueryEmbed.Qs.Query = search
+	if len(fieldList) == 1 {
+		q.QueryEmbed.Qs.DefaultField = fields
+	} else {
+		q.QueryEmbed.Qs.Fields = fieldList
+	}
+	q.QueryEmbed.Qs.Exists = exists
+	q.QueryEmbed.Qs.Missing = missing
+	return q
+}
+
+// Filter this query
+func (q *QueryDsl) Filter(f *FilterOp) *QueryDsl {
+	q.FilterVal = f
+	return q
+}
+
+type MatchAll struct {
+	All string `json:"-"`
+}
+
+// should we reuse QueryDsl here?
+type QueryWrap struct {
+	Qs QueryString `json:"query_string,omitempty"`
+}
+
+// QueryString based search
+func NewQueryString(field, query string) QueryString {
+	return QueryString{"", field, query, "", "", nil}
+}
+
+type QueryString struct {
+	DefaultOperator string   `json:"default_operator,omitempty"`
+	DefaultField    string   `json:"default_field,omitempty"`
+	Query           string   `json:"query,omitempty"`
+	Exists          string   `json:"_exists_,omitempty"`
+	Missing         string   `json:"_missing_,omitempty"`
+	Fields          []string `json:"fields,omitempty"`
+	//_exists_:field1,
+	//_missing_:field1,
+}
+
+// Generic Term based (used in query, facet, filter)
+type Term struct {
+	Terms Terms `json:"terms,omitempty"`
+}
+
+type Terms struct {
+	Fields []string `json:"field,omitempty"`
+	Size   string   `json:"size,omitempty"`
+	Regex  string   `json:"regex,omitempty"`
+}
+
+// Custom marshalling
+func (t *Terms) MarshalJSON() ([]byte, error) {
+	m := make(map[string]interface{})
+	// TODO:  this isn't getting called!?
+	if len(t.Fields) == 1 {
+		m["field"] = t.Fields[0]
+	} else if len(t.Fields) > 1 {
+		m["fields"] = t.Fields
+	}
+	if len(t.Regex) > 0 {
+		m["regex"] = t.Regex
+	}
+	if len(t.Size) > 0 {
+		m["size"] = t.Size
+	}
+	return json.Marshal(m)
+}
diff -ruN a/src/github.com/mattbaird/elastigo/search/search.go b/src/github.com/mattbaird/elastigo/search/search.go
--- a/src/github.com/mattbaird/elastigo/search/search.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/search.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,175 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"github.com/mattbaird/elastigo/core"
+	"log"
+	"net/url"
+	"strings"
+
+	u "github.com/araddon/gou"
+)
+
+var (
+	_ = u.DEBUG
+)
+
+// Search is the entry point to the SearchDsl, it is a chainable set of utilities
+// to create searches.
+//
+// params
+//    @index = elasticsearch index to search
+//
+//    out, err := Search("github").Type("Issues").Pretty().Query(
+//    Query().Range(
+//         Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+//       ).Search("add"),
+//     ).Result()
+func Search(index string) *SearchDsl {
+	return &SearchDsl{Index: index, args: url.Values{}}
+}
+
+type SearchDsl struct {
+	args      url.Values
+	types     []string
+	FromVal   int         `json:"from,omitempty"`
+	SizeVal   int         `json:"size,omitempty"`
+	Index     string      `json:"-"`
+	FacetVal  *FacetDsl   `json:"facets,omitempty"`
+	QueryVal  *QueryDsl   `json:"query,omitempty"`
+	SortBody  []*SortDsl  `json:"sort,omitempty"`
+	FilterVal *FilterWrap `json:"filter,omitempty"`
+}
+
+func (s *SearchDsl) Bytes() ([]byte, error) {
+	return api.DoCommand("POST", s.url(), s)
+}
+
+func (s *SearchDsl) Result() (*core.SearchResult, error) {
+	var retval core.SearchResult
+	if core.DebugRequests {
+		sb, _ := json.MarshalIndent(s, "  ", "  ")
+		log.Println(s.url())
+		log.Println(string(sb))
+	}
+	body, err := s.Bytes()
+	if err != nil {
+		u.Errorf("%v", err)
+		return nil, err
+	}
+	jsonErr := json.Unmarshal(body, &retval)
+	if jsonErr != nil {
+		u.Errorf("%v \n\t%s", jsonErr, string(body))
+	}
+	//Debug(string(body))
+	return &retval, jsonErr
+}
+
+func (s *SearchDsl) url() string {
+	url := fmt.Sprintf("/%s%s/_search?%s", s.Index, s.getType(), s.args.Encode())
+	return url
+}
+
+func (s *SearchDsl) Pretty() *SearchDsl {
+	s.args.Set("pretty", "1")
+	return s
+}
+
+// Type is the elasticsearch *Type* within a specific index
+func (s *SearchDsl) Type(indexType string) *SearchDsl {
+	if len(s.types) == 0 {
+		s.types = make([]string, 0)
+	}
+	s.types = append(s.types, indexType)
+	return s
+}
+
+func (s *SearchDsl) getType() string {
+	if len(s.types) > 0 {
+		return "/" + strings.Join(s.types, ",")
+	}
+	return ""
+}
+
+func (s *SearchDsl) From(from string) *SearchDsl {
+	s.args.Set("from", from)
+	return s
+}
+
+// Search is a simple interface to search, doesn't have the power of query
+// but uses a simple query_string search
+func (s *SearchDsl) Search(srch string) *SearchDsl {
+	s.QueryVal = Query().Search(srch)
+	return s
+}
+
+func (s *SearchDsl) Size(size string) *SearchDsl {
+	s.args.Set("size", size)
+	return s
+}
+
+// Facet passes a Query expression to this search
+//
+//		qry := Search("github").Size("0").Facet(
+//					Facet().Regex("repository.name", "no.*").Size("8"),
+//				)
+//
+//		qry := Search("github").Pretty().Facet(
+//					Facet().Fields("type").Size("25"),
+//				)
+func (s *SearchDsl) Facet(f *FacetDsl) *SearchDsl {
+	s.FacetVal = f
+	return s
+}
+
+func (s *SearchDsl) Query(q *QueryDsl) *SearchDsl {
+	s.QueryVal = q
+	return s
+}
+
+// Filter adds a Filter Clause with optional Boolean Clause.  This accepts n number of
+// filter clauses.  If more than one, and missing Boolean Clause it assumes "and"
+//
+//     qry := Search("github").Filter(
+//         Filter().Exists("repository.name"),
+//     )
+//
+//     qry := Search("github").Filter(
+//         "or",
+//         Filter().Exists("repository.name"),
+//         Filter().Terms("actor_attributes.location", "portland"),
+//     )
+//
+//     qry := Search("github").Filter(
+//         Filter().Exists("repository.name"),
+//         Filter().Terms("repository.has_wiki", true)
+//     )
+func (s *SearchDsl) Filter(fl ...interface{}) *SearchDsl {
+	if s.FilterVal == nil {
+		s.FilterVal = NewFilterWrap()
+	}
+
+	s.FilterVal.addFilters(fl)
+	return s
+}
+
+func (s *SearchDsl) Sort(sort ...*SortDsl) *SearchDsl {
+	if s.SortBody == nil {
+		s.SortBody = make([]*SortDsl, 0)
+	}
+	s.SortBody = append(s.SortBody, sort...)
+	return s
+}
diff -ruN a/src/github.com/mattbaird/elastigo/search/search_test.go b/src/github.com/mattbaird/elastigo/search/search_test.go
--- a/src/github.com/mattbaird/elastigo/search/search_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/search_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,310 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	u "github.com/araddon/gou"
+	"github.com/mattbaird/elastigo/core"
+	"log"
+	"testing"
+)
+
+var (
+	_ = log.Ldate
+)
+
+func TestSearchRequest(t *testing.T) {
+	qry := map[string]interface{}{
+		"query": map[string]interface{}{
+			"wildcard": map[string]string{"actor": "a*"},
+		},
+	}
+	out, err := core.SearchRequest(true, "github", "", qry, "", 0)
+	//log.Println(out)
+	u.Assert(&out != nil && err == nil, t, "Should get docs")
+	u.Assert(out.Hits.Total == 616 && out.Hits.Len() == 10, t, "Should have 616 hits but was %v", out.Hits.Total)
+}
+
+func TestSearchSimple(t *testing.T) {
+
+	// searching without faceting
+	qry := Search("github").Pretty().Query(
+		Query().Search("add"),
+	)
+	out, _ := qry.Result()
+	// how many different docs used the word "add"
+	u.Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 494, t, "Should have 494 total= %v", out.Hits.Total)
+
+	// now the same result from a "Simple" search
+	out, _ = Search("github").Search("add").Result()
+	u.Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 494, t, "Should have 494 total= %v", out.Hits.Total)
+}
+
+func TestSearchRequestQueryString(t *testing.T) {
+	out, err := core.SearchUri("github", "", "actor:a*", "", 0)
+	//log.Println(out)
+	u.Assert(&out != nil && err == nil, t, "Should get docs")
+	u.Assert(out.Hits.Total == 616, t, "Should have 616 hits but was %v", out.Hits.Total)
+}
+
+func TestSearchFacetOne(t *testing.T) {
+	/*
+		A faceted search for what "type" of events there are
+		- since we are not specifying an elasticsearch type it searches all ()
+
+		{
+		    "terms" : {
+		      "_type" : "terms",
+		      "missing" : 0,
+		      "total" : 7561,
+		      "other" : 0,
+		      "terms" : [ {
+		        "term" : "pushevent",
+		        "count" : 4185
+		      }, {
+		        "term" : "createevent",
+		        "count" : 786
+		      }.....]
+		    }
+		 }
+
+	*/
+	qry := Search("github").Pretty().Facet(
+		Facet().Fields("type").Size("25"),
+	).Query(
+		Query().All(),
+	).Size("1")
+	out, err := qry.Result()
+	//log.Println(string(out.Facets))
+	u.Debug(out)
+	u.Assert(out != nil && err == nil, t, "Should have output")
+	if out == nil {
+		t.Fail()
+		return
+	}
+	h := u.NewJsonHelper(out.Facets)
+	u.Assert(h.Int("type.total") == 8084, t, "Should have 8084 results %v", h.Int("type.total"))
+	u.Assert(len(h.List("type.terms")) == 16, t, "Should have 16 event types, %v", len(h.List("type.terms")))
+
+	// Now, lets try changing size to 10
+	qry.FacetVal.Size("10")
+	out, err = qry.Result()
+	h = u.NewJsonHelper(out.Facets)
+
+	// still same doc count
+	u.Assert(h.Int("type.total") == 8084, t, "Should have 8084 results %v", h.Int("type.total"))
+	// make sure size worked
+	u.Assert(len(h.List("type.terms")) == 10, t, "Should have 10 event types, %v", len(h.List("type.terms")))
+
+	// now, lets add a type (out of the 16)
+	out, _ = Search("github").Type("IssueCommentEvent").Pretty().Facet(
+		Facet().Fields("type").Size("25"),
+	).Query(
+		Query().All(),
+	).Result()
+	h = u.NewJsonHelper(out.Facets)
+	//log.Println(string(out.Facets))
+	// still same doc count
+	u.Assert(h.Int("type.total") == 685, t, "Should have 685 results %v", h.Int("type.total"))
+	// we should only have one facettype because we limited to one type
+	u.Assert(len(h.List("type.terms")) == 1, t, "Should have 1 event types, %v", len(h.List("type.terms")))
+
+	// now, add a second type (chained)
+	out, _ = Search("github").Type("IssueCommentEvent").Type("PushEvent").Pretty().Facet(
+		Facet().Fields("type").Size("25"),
+	).Query(
+		Query().All(),
+	).Result()
+	h = u.NewJsonHelper(out.Facets)
+	//log.Println(string(out.Facets))
+	// still same doc count
+	u.Assert(h.Int("type.total") == 4941, t, "Should have 4941 results %v", h.Int("type.total"))
+	// make sure we now have 2 types
+	u.Assert(len(h.List("type.terms")) == 2, t, "Should have 2 event types, %v", len(h.List("type.terms")))
+
+	//and instead of faceting on type, facet on userid
+	// now, add a second type (chained)
+	out, _ = Search("github").Type("IssueCommentEvent,PushEvent").Pretty().Facet(
+		Facet().Fields("actor").Size("500"),
+	).Query(
+		Query().All(),
+	).Result()
+	h = u.NewJsonHelper(out.Facets)
+	// still same doc count
+	u.Assert(h.Int("actor.total") == 5158, t, "Should have 5158 results %v", h.Int("actor.total"))
+	// make sure size worked
+	u.Assert(len(h.List("actor.terms")) == 500, t, "Should have 500 users, %v", len(h.List("actor.terms")))
+
+}
+
+func TestSearchFacetRange(t *testing.T) {
+	// ok, now lets try facet but on actor field with a range
+	qry := Search("github").Pretty().Facet(
+		Facet().Fields("actor").Size("500"),
+	).Query(
+		Query().Search("add"),
+	)
+	out, err := qry.Result()
+	u.Assert(out != nil && err == nil, t, "Should have output")
+
+	if out == nil {
+		t.Fail()
+		return
+	}
+	//log.Println(string(out.Facets))
+	h := u.NewJsonHelper(out.Facets)
+	// how many different docs used the word "add", during entire time range
+	u.Assert(h.Int("actor.total") == 521, t, "Should have 521 results %v", h.Int("actor.total"))
+	// make sure size worked
+	u.Assert(len(h.List("actor.terms")) == 366, t, "Should have 366 unique userids, %v", len(h.List("actor.terms")))
+
+	// ok, repeat but with a range showing different results
+	qry = Search("github").Pretty().Facet(
+		Facet().Fields("actor").Size("500"),
+	).Query(
+		Query().Range(
+			Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+		).Search("add"),
+	)
+	out, err = qry.Result()
+	u.Assert(out != nil && err == nil, t, "Should have output")
+
+	if out == nil {
+		t.Fail()
+		return
+	}
+	//log.Println(string(out.Facets))
+	h = u.NewJsonHelper(out.Facets)
+	// how many different events used the word "add", during time range?
+	u.Assert(h.Int("actor.total") == 97, t, "Should have 97 results %v", h.Int("actor.total"))
+	// make sure size worked
+	u.Assert(len(h.List("actor.terms")) == 71, t, "Should have 71 event types, %v", len(h.List("actor.terms")))
+
+}
+
+func TestSearchTerm(t *testing.T) {
+
+	// ok, now lets try searching with term query (specific field/term)
+	qry := Search("github").Query(
+		Query().Term("repository.name", "jasmine"),
+	)
+	out, _ := qry.Result()
+	// how many different docs have jasmine in repository.name?
+	u.Assert(out.Hits.Len() == 4, t, "Should have 4 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 4, t, "Should have 4 total= %v", out.Hits.Total)
+
+}
+
+func TestSearchFields(t *testing.T) {
+	// same as terms, search using fields:
+	//    how many different docs have jasmine in repository.name?
+	qry := Search("github").Query(
+		Query().Fields("repository.name", "jasmine", "", ""),
+	)
+	out, _ := qry.Result()
+
+	u.Assert(out.Hits.Len() == 4, t, "Should have 4 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 4, t, "Should have 4 total= %v", out.Hits.Total)
+}
+
+func TestSearchMissingExists(t *testing.T) {
+	// search for docs that are missing repository.name
+	qry := Search("github").Filter(
+		Filter().Exists("repository.name"),
+	)
+	out, _ := qry.Result()
+	u.Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 7695, t, "Should have 7695 total= %v", out.Hits.Total)
+
+	qry = Search("github").Filter(
+		Filter().Missing("repository.name"),
+	)
+	out, _ = qry.Result()
+	u.Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 389, t, "Should have 389 total= %v", out.Hits.Total)
+}
+
+func TestSearchFilterQuery(t *testing.T) {
+
+	// compound query + filter with query being wildcard
+	out, _ := Search("github").Size("25").Query(
+		Query().Fields("repository.name", "jas*", "", ""),
+	).Filter(
+		Filter().Terms("repository.has_wiki", true),
+	).Result()
+	if out == nil || &out.Hits == nil {
+		t.Fail()
+		return
+	}
+
+	u.Assert(out.Hits.Len() == 7, t, "Should have 7 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 7, t, "Should have total=7 but was %v", out.Hits.Total)
+}
+
+func TestSearchRange(t *testing.T) {
+
+	// now lets filter by a subset of the total time
+	out, _ := Search("github").Size("25").Query(
+		Query().Range(
+			Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+		).Search("add"),
+	).Result()
+	u.Assert(out != nil && &out.Hits != nil, t, "Must not have nil results, or hits")
+	u.Assert(out.Hits.Len() == 25, t, "Should have 25 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 92, t, "Should have total=92 but was %v", out.Hits.Total)
+}
+
+func TestSearchSortOrder(t *testing.T) {
+
+	// ok, now lets try sorting by repository watchers descending
+	qry := Search("github").Pretty().Query(
+		Query().All(),
+	).Sort(
+		Sort("repository.watchers").Desc(),
+	)
+	out, _ := qry.Result()
+
+	// how many different docs used the word "add", during entire time range
+	u.Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 8084, t, "Should have 8084 total= %v", out.Hits.Total)
+	h1 := u.NewJsonHelper(out.Hits.Hits[0].Source)
+	u.Assert(h1.Int("repository.watchers") == 41377, t, "Should have 41377 watchers= %v", h1.Int("repository.watchers"))
+
+	// ascending
+	out, _ = Search("github").Pretty().Query(
+		Query().All(),
+	).Sort(
+		Sort("repository.watchers"),
+	).Result()
+	// how many different docs used the word "add", during entire time range
+	u.Assert(out.Hits.Len() == 10, t, "Should have 10 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 8084, t, "Should have 8084 total= %v", out.Hits.Total)
+	h2 := u.NewJsonHelper(out.Hits.Hits[0].Source)
+	u.Assert(h2.Int("repository.watchers") == 0, t, "Should have 0 watchers= %v", h2.Int("repository.watchers"))
+
+	// sort descending with search
+	out, _ = Search("github").Pretty().Size("5").Query(
+		Query().Search("python"),
+	).Sort(
+		Sort("repository.watchers").Desc(),
+	).Result()
+	//log.Println(out)
+	//log.Println(err)
+	// how many different docs used the word "add", during entire time range
+	u.Assert(out.Hits.Len() == 5, t, "Should have 5 docs %v", out.Hits.Len())
+	u.Assert(out.Hits.Total == 734, t, "Should have 734 total= %v", out.Hits.Total)
+	h3 := u.NewJsonHelper(out.Hits.Hits[0].Source)
+	u.Assert(h3.Int("repository.watchers") == 8659, t, "Should have 8659 watchers= %v", h3.Int("repository.watchers"))
+
+}
diff -ruN a/src/github.com/mattbaird/elastigo/search/sort.go b/src/github.com/mattbaird/elastigo/search/sort.go
--- a/src/github.com/mattbaird/elastigo/search/sort.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/sort.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,52 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+	"fmt"
+)
+
+// SortDsl accepts any number of Sort commands
+//
+//     Query().Sort(
+//         Sort("last_name").Desc(),
+//         Sort("age"),
+//     )
+func Sort(field string) *SortDsl {
+	return &SortDsl{Name: field}
+}
+
+type SortBody []interface{}
+type SortDsl struct {
+	Name   string
+	IsDesc bool
+}
+
+func (s *SortDsl) Desc() *SortDsl {
+	s.IsDesc = true
+	return s
+}
+func (s *SortDsl) Asc() *SortDsl {
+	s.IsDesc = false
+	return s
+}
+
+func (s *SortDsl) MarshalJSON() ([]byte, error) {
+	if s.IsDesc {
+		return json.Marshal(map[string]string{s.Name: "desc"})
+	}
+	if s.Name == "_score" {
+		return []byte(`"_score"`), nil
+	}
+	return []byte(fmt.Sprintf(`"%s"`, s.Name)), nil // "user"  assuming default = asc?
+}
diff -ruN a/src/github.com/mattbaird/elastigo/search/test_test.go b/src/github.com/mattbaird/elastigo/search/test_test.go
--- a/src/github.com/mattbaird/elastigo/search/test_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/search/test_test.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,55 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"flag"
+	"github.com/araddon/gou"
+	"github.com/mattbaird/elastigo/api"
+	"github.com/mattbaird/elastigo/core"
+	"log"
+	"os"
+	//"testing"
+)
+
+var (
+	_                 = log.Ldate
+	hasStartedTesting bool
+	eshost            *string = flag.String("host", "localhost", "Elasticsearch Server Host Address")
+	logLevel          *string = flag.String("logging", "info", "Which log level: [debug,info,warn,error,fatal]")
+)
+
+/*
+
+usage:
+
+	test -v -host eshost
+
+*/
+
+func init() {
+	InitTests(false)
+	if *logLevel == "debug" {
+		//*logLevel = "debug"
+		core.DebugRequests = true
+	}
+}
+
+func InitTests(startIndexer bool) {
+	if !hasStartedTesting {
+		flag.Parse()
+		hasStartedTesting = true
+		gou.SetLogger(log.New(os.Stderr, "", log.Ltime|log.Lshortfile), *logLevel)
+		log.SetFlags(log.Ltime | log.Lshortfile)
+		api.Domain = *eshost
+	}
+}
diff -ruN a/src/github.com/mattbaird/elastigo/tutorial/README.md b/src/github.com/mattbaird/elastigo/tutorial/README.md
--- a/src/github.com/mattbaird/elastigo/tutorial/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/tutorial/README.md	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,11 @@
+
+
+Tutorials
+=======================================
+
+To run these tutorials::
+	
+
+	go run start_1.go
+
+	# etc
\ No newline at end of file
diff -ruN a/src/github.com/mattbaird/elastigo/tutorial/start_1.go b/src/github.com/mattbaird/elastigo/tutorial/start_1.go
--- a/src/github.com/mattbaird/elastigo/tutorial/start_1.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/mattbaird/elastigo/tutorial/start_1.go	2014-01-15 15:02:30.000000000 +0000
@@ -0,0 +1,71 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package main
+
+import (
+	"flag"
+	"fmt"
+	"github.com/mattbaird/elastigo/api"
+	"github.com/mattbaird/elastigo/core"
+	"log"
+	"os"
+)
+
+var (
+	host *string = flag.String("host", "localhost", "Elasticsearch Host")
+)
+
+func main() {
+	core.DebugRequests = true
+	log.SetFlags(log.LstdFlags)
+	flag.Parse()
+
+	fmt.Println("host = ", *host)
+	// Set the Elasticsearch Host to Connect to
+	api.Domain = *host
+
+	// Index a document
+	_, err := core.Index(false, "testindex", "user", "docid_1", `{"name":"bob"}`)
+	exitIfErr(err)
+
+	// Index a doc using a map of values
+	_, err = core.Index(false, "testindex", "user", "docid_2", map[string]string{"name": "venkatesh"})
+	exitIfErr(err)
+
+	// Index a doc using Structs
+	_, err = core.Index(false, "testindex", "user", "docid_3", MyUser{"wanda", 22})
+	exitIfErr(err)
+
+	// Search Using Raw json String
+	searchJson := `{
+	    "query" : {
+	        "term" : { "Name" : "wanda" }
+	    }
+	}`
+	out, err := core.SearchRequest(true, "testindex", "user", searchJson, "", 0)
+	if len(out.Hits.Hits) == 1 {
+		fmt.Println(string(out.Hits.Hits[0].Source))
+	}
+	exitIfErr(err)
+
+}
+func exitIfErr(err error) {
+	if err != nil {
+		fmt.Fprintf(os.Stderr, "Error: %s\n", err.Error())
+		os.Exit(1)
+	}
+}
+
+type MyUser struct {
+	Name string
+	Age  int
+}
